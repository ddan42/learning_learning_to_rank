{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgNjgQaBTYC4",
        "outputId": "d6d82466-5fb6-4c07-97bc-0f00af1cab5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2022.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQt1CwTFTloQ",
        "outputId": "651fb0ac-ae5b-4e52-a219-8afb2662cb18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.11.1)\n",
            "Requirement already satisfied: cmaes>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from optuna) (0.10.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.19)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.7.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMvWobQeTaG8"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import pickle\n",
        "import random\n",
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "from catboost.datasets import msrank_10k\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnB7txivTaOT"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABwO7ZNDTaRC"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6G-XNr2Tjf1"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zePPIzDUTaT7"
      },
      "outputs": [],
      "source": [
        "class LambdaMART_10k():\n",
        "    def __init__(self, n_estimators: int = 100, lr: float = 0.5, ndcg_top_k: int = 10,\n",
        "                 subsample: float = 0.6, colsample_bytree: float = 0.9,\n",
        "                 max_depth: int = 5, min_samples_leaf: int = 8):\n",
        "        self._prepare_data()\n",
        "\n",
        "        self.ndcg_top_k = ndcg_top_k\n",
        "        self.n_estimators = n_estimators\n",
        "        self.lr = lr\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "\n",
        "        self.subsample = subsample\n",
        "        self.colsample_bytree = colsample_bytree\n",
        "\n",
        "    def _get_data(self) -> List[np.ndarray]:\n",
        "        train_df, test_df = msrank_10k()\n",
        "\n",
        "        X_train = train_df.drop([0, 1], axis=1).values\n",
        "        y_train = train_df[0].values\n",
        "        query_ids_train = train_df[1].values.astype(int)\n",
        "\n",
        "        X_test = test_df.drop([0, 1], axis=1).values\n",
        "        y_test = test_df[0].values\n",
        "        query_ids_test = test_df[1].values.astype(int)\n",
        "\n",
        "        return [X_train, y_train, query_ids_train, X_test, y_test, query_ids_test]\n",
        "\n",
        "    def _prepare_data(self) -> None:\n",
        "        (X_train, y_train, self.query_ids_train,\n",
        "            X_test, y_test, self.query_ids_test) = self._get_data()\n",
        "\n",
        "        self.X_train = torch.FloatTensor(self._scale_features_in_query_groups(X_train, self.query_ids_train))\n",
        "        self.y_train = torch.FloatTensor(y_train).reshape(-1, 1)\n",
        "\n",
        "        self.X_test = torch.FloatTensor(self._scale_features_in_query_groups(X_test, self.query_ids_test))\n",
        "        self.y_test = torch.FloatTensor(y_test).reshape(-1, 1)\n",
        "\n",
        "\n",
        "    def _scale_features_in_query_groups(self, inp_feat_array: np.ndarray,\n",
        "                                        inp_query_ids: np.ndarray) -> np.ndarray:\n",
        "        query_idx = {query: [] for query in np.unique(inp_query_ids)}\n",
        "        scaler = StandardScaler()\n",
        "        for idx, query in enumerate(inp_query_ids, 0):\n",
        "            query_idx[query].append(idx)\n",
        "        for query in query_idx:\n",
        "            inp_feat_array[query_idx[query]] = scaler.fit_transform(inp_feat_array[query_idx[query]])\n",
        "        return inp_feat_array\n",
        "\n",
        "    def _train_one_tree(self, cur_tree_idx: int,\n",
        "                        train_preds: torch.FloatTensor\n",
        "                        ) -> Tuple[DecisionTreeRegressor, np.ndarray]:\n",
        "        np.random.seed(cur_tree_idx)\n",
        "\n",
        "        tree = DecisionTreeRegressor(max_depth = self.max_depth,\n",
        "                                     min_samples_leaf = self.min_samples_leaf,\n",
        "                                     random_state = cur_tree_idx)\n",
        "\n",
        "        X_rows_index = range(self.X_train.shape[0])\n",
        "        X_cols_index = range(self.X_train.shape[1])\n",
        "        rows_n = int(self.subsample*self.X_train.shape[0])\n",
        "        cols_n = int(self.colsample_bytree*self.X_train.shape[1])\n",
        "\n",
        "        X_tree_rows = torch.IntTensor(np.random.choice(X_rows_index, rows_n, replace = False).tolist())\n",
        "        X_tree_cols = torch.IntTensor(np.random.choice(X_cols_index, cols_n, replace = False).tolist())\n",
        "\n",
        "        X_tree_fit = torch.index_select(torch.index_select(self.X_train, 1, X_tree_cols),\n",
        "                                0, X_tree_rows)\n",
        "        y_preds_tree = torch.index_select(self.y_train, 0, X_tree_rows)\n",
        "        train_preds_tree = torch.index_select(train_preds, 0, X_tree_rows)\n",
        "\n",
        "        queries_tree = self.query_ids_train[X_tree_rows]\n",
        "\n",
        "        query_idx = {query: [] for query in np.unique(queries_tree)}\n",
        "        for idx, query in enumerate(queries_tree, 0):\n",
        "            query_idx[query].append(idx)\n",
        "\n",
        "        l = torch.zeros(X_tree_fit.shape[0])\n",
        "\n",
        "        for query, idx in query_idx.items():\n",
        "            rows_idx = torch.IntTensor(idx)\n",
        "            y_query = torch.index_select(y_preds_tree, 0, rows_idx)\n",
        "            y_preds = torch.index_select(train_preds_tree, 0, rows_idx)\n",
        "            l_q = self._compute_lambdas(y_query, y_preds)\n",
        "            l_q = l_q.sum(dim = 1)\n",
        "            for row, l_q_v in zip(rows_idx, l_q):\n",
        "                l[row.item()] = l_q_v.item()\n",
        "\n",
        "        tree.fit(X_tree_fit.numpy(), -l.numpy())\n",
        "        return tree, X_tree_cols\n",
        "\n",
        "    def _calc_data_ndcg(self, queries_list: np.ndarray,\n",
        "                        true_labels: torch.FloatTensor, preds: torch.FloatTensor) -> float:\n",
        "        ndcgs = []\n",
        "        query_idx = {query: [] for query in np.unique(queries_list)}\n",
        "        scaler = StandardScaler()\n",
        "        for idx, query in enumerate(queries_list, 0):\n",
        "            query_idx[query].append(idx)\n",
        "        for query in query_idx:\n",
        "            ndcg = self._ndcg_k(true_labels[query_idx[query]], preds[query_idx[query]], self.ndcg_top_k)\n",
        "            if np.isnan(ndcg):\n",
        "                ndcg = 0\n",
        "            ndcgs.append(ndcg)\n",
        "        return np.mean(ndcgs)\n",
        "\n",
        "    def fit(self, print_training = None):\n",
        "        np.random.seed(0)\n",
        "\n",
        "        train_preds = torch.zeros(self.y_train.shape)\n",
        "        train_ndcgs = []\n",
        "\n",
        "        train_list = []\n",
        "\n",
        "        test_preds = torch.zeros(self.y_test.shape)\n",
        "        test_ndcgs = []\n",
        "\n",
        "        self.cols_list = []\n",
        "        self.trees = []\n",
        "        self.preds_list = []\n",
        "\n",
        "        for i in range(self.n_estimators):\n",
        "            tree, cols = self._train_one_tree(i, train_preds)\n",
        "            self.trees.append(tree)\n",
        "            self.cols_list.append(cols)\n",
        "\n",
        "            train_list.append(train_preds)\n",
        "\n",
        "            train_preds += self.lr*torch.FloatTensor(tree.predict(torch.index_select(self.X_train, 1, cols).numpy())).reshape(-1, 1)\n",
        "            train_score = self._calc_data_ndcg(self.query_ids_train, self.y_train, train_preds)\n",
        "            train_ndcgs.append(train_score)\n",
        "\n",
        "            test_preds += torch.FloatTensor(tree.predict(torch.index_select(self.X_test, 1, cols).numpy())).reshape(-1, 1)\n",
        "            test_score = self._calc_data_ndcg(self.query_ids_test, self.y_test, test_preds)\n",
        "            test_ndcgs.append(test_score)\n",
        "\n",
        "            if print_training:\n",
        "                print(f'Tree {i} ndcg@{self.ndcg_top_k}: train = {train_score}, test = {test_score}')\n",
        "        if print_training:\n",
        "            plt.plot(range(self.n_estimators), train_ndcgs)\n",
        "            plt.plot(range(self.n_estimators), test_ndcgs)\n",
        "            plt.legend(['train_ndcg', 'test_ndcg'])\n",
        "\n",
        "        max_ndcg_idx = test_ndcgs.index(max(test_ndcgs))\n",
        "        self.best_ndcg = test_ndcgs[max_ndcg_idx]\n",
        "        self.trees = self.trees[:max_ndcg_idx+1]\n",
        "        self.cols_list = self.cols_list[:max_ndcg_idx+1]\n",
        "        return self.best_ndcg\n",
        "\n",
        "    def predict(self, data: torch.FloatTensor) -> torch.FloatTensor:\n",
        "        preds = torch.zeros(data.shape[0], 1)\n",
        "\n",
        "        for tree, cols in zip(self.trees, self.cols_list):\n",
        "            tree_preds = torch.FloatTensor(tree.predict(torch.index_select(data, 1, cols).numpy())).reshape(-1, 1)\n",
        "            preds += self.lr*tree_preds\n",
        "        return preds\n",
        "\n",
        "    def _compute_lambdas(self, y_true: torch.FloatTensor, y_pred: torch.FloatTensor) -> torch.FloatTensor:\n",
        "        # dnDCG = (1/ideal_dcg)*(gain_diff)*(logs_diff)\n",
        "\n",
        "        ideal_dcg = self._ideal_dcg(y_true)\n",
        "        N = 1/ideal_dcg\n",
        "        if np.isnan(N) or ideal_dcg == 0:\n",
        "            N = 0\n",
        "        _, rank_order = torch.sort(y_true, descending=True, axis=0)\n",
        "        rank_order += 1\n",
        "\n",
        "        gain_diff = torch.pow(2, y_true)-torch.pow(2, y_true.t())\n",
        "\n",
        "        decay_diff = (1.0 / torch.log2(rank_order + 1.0)) - (1.0 / torch.log2(rank_order.t() + 1.0))\\\n",
        "\n",
        "        dnDCG = torch.abs(N * gain_diff * decay_diff)\n",
        "\n",
        "        pos_pairs_score_diff = 1.0 + torch.exp((y_pred - y_pred.t()))\n",
        "        # Sij\n",
        "        scores_diff = y_true-y_true.t()\n",
        "        pos_pairs = (scores_diff>0).type(torch.int32)\n",
        "        neg_pairs = (scores_diff<0).type(torch.int32)\n",
        "        Sij = pos_pairs - neg_pairs\n",
        "\n",
        "        # (0.5 * (1 - Sij) - 1 / pos_pairs_score_diff)*dnDCG\n",
        "        return (0.5 * (1 - Sij) - 1 / pos_pairs_score_diff)*dnDCG\n",
        "\n",
        "    def _ndcg_k(self, ys_true, ys_pred, ndcg_top_k) -> float:\n",
        "        def dcg(ys_true, ys_pred):\n",
        "            _, argsort = torch.sort(ys_pred, descending=True, dim=0)\n",
        "            argsort = argsort[:ndcg_top_k]\n",
        "            ys_true_sorted = ys_true[argsort]\n",
        "            gain = 0\n",
        "            for i, l in enumerate(ys_true_sorted, 1):\n",
        "                gain += (2 ** l - 1) / math.log2(1 + i)\n",
        "            return gain\n",
        "        ideal_dcg = dcg(ys_true, ys_true)\n",
        "        pred_dcg = dcg(ys_true, ys_pred)\n",
        "        return (pred_dcg / ideal_dcg).item()\n",
        "\n",
        "    def _ideal_dcg(self, ys_true) -> float:\n",
        "        def dcg(ys_true, ys_pred):\n",
        "            _, argsort = torch.sort(ys_pred, descending=True, dim=0)\n",
        "            ys_true_sorted = ys_true[argsort]\n",
        "            gain = 0\n",
        "            for i, l in enumerate(ys_true_sorted, 1):\n",
        "                gain += (2 ** l - 1) / math.log2(1 + i)\n",
        "            return gain\n",
        "        return dcg(ys_true, ys_true)\n",
        "    def save_model(self, path: str):\n",
        "        state = {\n",
        "            'trees': self.trees,\n",
        "            'trees_feat_idxs': self.trees_feat_idxs,\n",
        "            'lr': self.lr\n",
        "        }\n",
        "        f = open(path, 'wb')\n",
        "        pickle.dump(state, f)\n",
        "\n",
        "    def load_model(self, path: str):\n",
        "        f = open(path, 'rb')\n",
        "        state = pickle.load(f)\n",
        "        self.trees = state['trees']\n",
        "        self.trees_feat_idxs = state['trees_feat_idxs']\n",
        "        self.lr = state['lr']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Jc0fCeQTYE8L",
        "outputId": "aebb8ce9-0915-4378-cd2f-c1e0d7ee317a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-08-01 16:15:49,903] A new study created in memory with name: no-name-d333399e-f17a-4c93-8cd3-f2904db68db4\n",
            "[I 2023-08-01 16:20:32,790] Trial 0 finished with value: 0.4306043646806343 and parameters: {'n_estimators': 186, 'lr': 0.6045199074684007, 'subsample': 0.9773745795569279, 'colsample_bytree': 0.908677330739053, 'max_depth': 7, 'min_samples_leaf': 20}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 16:21:55,437] Trial 1 finished with value: 0.3607463827780025 and parameters: {'n_estimators': 111, 'lr': 0.6663037713170612, 'subsample': 0.7083072087904595, 'colsample_bytree': 0.1929234375469661, 'max_depth': 8, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 16:23:20,105] Trial 2 finished with value: 0.3852276294280521 and parameters: {'n_estimators': 131, 'lr': 0.36647657926317023, 'subsample': 0.684837223904673, 'colsample_bytree': 0.0949696875527069, 'max_depth': 4, 'min_samples_leaf': 12}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 16:26:54,554] Trial 3 finished with value: 0.4069629063702781 and parameters: {'n_estimators': 159, 'lr': 0.8140932935437645, 'subsample': 0.9589428789559818, 'colsample_bytree': 0.8102119694510269, 'max_depth': 7, 'min_samples_leaf': 14}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 16:28:56,101] Trial 4 finished with value: 0.38460176378827204 and parameters: {'n_estimators': 144, 'lr': 0.6162637495445245, 'subsample': 0.8214909666817483, 'colsample_bytree': 0.36105420508243846, 'max_depth': 5, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 16:30:02,127] Trial 5 finished with value: 0.40340099009600555 and parameters: {'n_estimators': 125, 'lr': 0.29528024412331355, 'subsample': 0.2671494473318608, 'colsample_bytree': 0.7492370132255747, 'max_depth': 6, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 16:32:51,369] Trial 6 finished with value: 0.4083781732796607 and parameters: {'n_estimators': 185, 'lr': 0.5534177314412773, 'subsample': 0.8945296855823044, 'colsample_bytree': 0.6905536855296418, 'max_depth': 3, 'min_samples_leaf': 12}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 16:34:30,418] Trial 7 finished with value: 0.4030472032979808 and parameters: {'n_estimators': 116, 'lr': 0.40935761065410403, 'subsample': 0.7358041707198868, 'colsample_bytree': 0.5452441937324972, 'max_depth': 5, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 16:35:13,203] Trial 8 finished with value: 0.4071943116035651 and parameters: {'n_estimators': 51, 'lr': 0.04039816007031552, 'subsample': 0.6184120668594791, 'colsample_bytree': 0.650779994613276, 'max_depth': 5, 'min_samples_leaf': 12}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 16:35:54,673] Trial 9 finished with value: 0.41757348497313534 and parameters: {'n_estimators': 57, 'lr': 0.823615298796941, 'subsample': 0.37896467547614926, 'colsample_bytree': 0.6644023145512091, 'max_depth': 10, 'min_samples_leaf': 20}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 16:36:56,154] Trial 10 finished with value: 0.33803072114559735 and parameters: {'n_estimators': 199, 'lr': 0.9700194861154723, 'subsample': 0.04461521711970501, 'colsample_bytree': 0.963507703928116, 'max_depth': 9, 'min_samples_leaf': 20}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 16:37:43,453] Trial 11 finished with value: 0.4040800261057236 and parameters: {'n_estimators': 50, 'lr': 0.7960684873791326, 'subsample': 0.45573759731895913, 'colsample_bytree': 0.9323930241650527, 'max_depth': 10, 'min_samples_leaf': 20}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 16:39:59,277] Trial 12 finished with value: 0.4120929090475494 and parameters: {'n_estimators': 86, 'lr': 0.963783734056346, 'subsample': 0.9791644150443702, 'colsample_bytree': 0.8409695945940671, 'max_depth': 10, 'min_samples_leaf': 17}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 16:40:59,527] Trial 13 finished with value: 0.40589620833369816 and parameters: {'n_estimators': 86, 'lr': 0.7163554546874736, 'subsample': 0.4304866516112254, 'colsample_bytree': 0.5388136898940067, 'max_depth': 8, 'min_samples_leaf': 16}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 16:43:40,590] Trial 14 finished with value: 0.41729205423458055 and parameters: {'n_estimators': 171, 'lr': 0.5232513170029824, 'subsample': 0.5479414078981806, 'colsample_bytree': 0.9921295916709313, 'max_depth': 7, 'min_samples_leaf': 18}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 16:44:42,771] Trial 15 finished with value: 0.41076024139130657 and parameters: {'n_estimators': 86, 'lr': 0.8917649555764198, 'subsample': 0.3496320238905814, 'colsample_bytree': 0.8353911692581057, 'max_depth': 9, 'min_samples_leaf': 15}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 16:46:01,746] Trial 16 finished with value: 0.42436746567149053 and parameters: {'n_estimators': 68, 'lr': 0.7463155735917657, 'subsample': 0.8611172548675636, 'colsample_bytree': 0.6532263748823702, 'max_depth': 8, 'min_samples_leaf': 18}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 16:48:28,727] Trial 17 finished with value: 0.4017733725380491 and parameters: {'n_estimators': 154, 'lr': 0.7169414596074005, 'subsample': 0.8481288894957655, 'colsample_bytree': 0.3887012364573157, 'max_depth': 8, 'min_samples_leaf': 17}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 16:50:05,975] Trial 18 finished with value: 0.42357136063616385 and parameters: {'n_estimators': 98, 'lr': 0.55820654605751, 'subsample': 0.8046202412660604, 'colsample_bytree': 0.5914452380030933, 'max_depth': 6, 'min_samples_leaf': 18}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 16:54:26,154] Trial 19 finished with value: 0.4070512793153863 and parameters: {'n_estimators': 200, 'lr': 0.6550932090844004, 'subsample': 0.9781116002820573, 'colsample_bytree': 0.7549752154013918, 'max_depth': 7, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 16:55:58,552] Trial 20 finished with value: 0.4203778917858885 and parameters: {'n_estimators': 64, 'lr': 0.45864428999685, 'subsample': 0.878287356291862, 'colsample_bytree': 0.8924990373178683, 'max_depth': 9, 'min_samples_leaf': 19}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 16:57:35,214] Trial 21 finished with value: 0.42007754036140715 and parameters: {'n_estimators': 101, 'lr': 0.5608072035175593, 'subsample': 0.7882038355258195, 'colsample_bytree': 0.5984311854875456, 'max_depth': 6, 'min_samples_leaf': 18}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 16:58:50,579] Trial 22 finished with value: 0.4006529866971753 and parameters: {'n_estimators': 71, 'lr': 0.5912504642700499, 'subsample': 0.7923219421863499, 'colsample_bytree': 0.723064231970252, 'max_depth': 6, 'min_samples_leaf': 14}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 17:00:10,793] Trial 23 finished with value: 0.37804302924566646 and parameters: {'n_estimators': 74, 'lr': 0.7398425551202596, 'subsample': 0.9145015899797979, 'colsample_bytree': 0.47290040941373124, 'max_depth': 7, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 17:02:13,943] Trial 24 finished with value: 0.42682648526335304 and parameters: {'n_estimators': 96, 'lr': 0.49721443103474683, 'subsample': 0.9809211883966193, 'colsample_bytree': 0.6233773632644527, 'max_depth': 8, 'min_samples_leaf': 18}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 17:04:03,150] Trial 25 finished with value: 0.41515050057999114 and parameters: {'n_estimators': 77, 'lr': 0.47605359835872996, 'subsample': 0.9873296105861947, 'colsample_bytree': 0.801037975243554, 'max_depth': 8, 'min_samples_leaf': 16}. Best is trial 0 with value: 0.4306043646806343.\n",
            "[I 2023-08-01 17:07:23,586] Trial 26 finished with value: 0.4324032929725945 and parameters: {'n_estimators': 139, 'lr': 0.663660151737296, 'subsample': 0.8909986782995061, 'colsample_bytree': 0.891973983433568, 'max_depth': 9, 'min_samples_leaf': 19}. Best is trial 26 with value: 0.4324032929725945.\n",
            "[I 2023-08-01 17:11:41,803] Trial 27 finished with value: 0.4324944074773653 and parameters: {'n_estimators': 175, 'lr': 0.6196291225251893, 'subsample': 0.918126554572848, 'colsample_bytree': 0.9059311624006442, 'max_depth': 9, 'min_samples_leaf': 19}. Best is trial 27 with value: 0.4324944074773653.\n",
            "[I 2023-08-01 17:16:04,256] Trial 28 finished with value: 0.43144981148229405 and parameters: {'n_estimators': 180, 'lr': 0.6379383978365664, 'subsample': 0.909921726325756, 'colsample_bytree': 0.8769640689442094, 'max_depth': 9, 'min_samples_leaf': 19}. Best is trial 27 with value: 0.4324944074773653.\n",
            "[I 2023-08-01 17:20:21,226] Trial 29 finished with value: 0.41712452503005887 and parameters: {'n_estimators': 179, 'lr': 0.6465049197034966, 'subsample': 0.8893448642307824, 'colsample_bytree': 0.8868170113071325, 'max_depth': 9, 'min_samples_leaf': 19}. Best is trial 27 with value: 0.4324944074773653.\n",
            "[W 2023-08-01 17:23:52,443] Trial 30 failed with parameters: {'n_estimators': 164, 'lr': 0.6258273269025441, 'subsample': 0.7529537605434412, 'colsample_bytree': 0.9097401719548478, 'max_depth': 10, 'min_samples_leaf': 16} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-8-475c9fb5ee95>\", line 9, in objective\n",
            "    score = LambdaMART_10k(n_estimators, lr, ndcg_top_k, subsample, colsample_bytree, max_depth, min_samples_leaf).fit()\n",
            "  File \"<ipython-input-7-7a7107724006>\", line 129, in fit\n",
            "    train_score = self._calc_data_ndcg(self.query_ids_train, self.y_train, train_preds)\n",
            "  File \"<ipython-input-7-7a7107724006>\", line 100, in _calc_data_ndcg\n",
            "    ndcg = self._ndcg_k(true_labels[query_idx[query]], preds[query_idx[query]], self.ndcg_top_k)\n",
            "  File \"<ipython-input-7-7a7107724006>\", line 191, in _ndcg_k\n",
            "    ideal_dcg = dcg(ys_true, ys_true)\n",
            "  File \"<ipython-input-7-7a7107724006>\", line 189, in dcg\n",
            "    gain += (2 ** l - 1) / math.log2(1 + i)\n",
            "KeyboardInterrupt\n",
            "[W 2023-08-01 17:23:52,448] Trial 30 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-475c9fb5ee95>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \"\"\"\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    444\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-475c9fb5ee95>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmin_samples_leaf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'min_samples_leaf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mndcg_top_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambdaMART_10k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndcg_top_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolsample_bytree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-7a7107724006>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, print)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mtrain_preds\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calc_data_ndcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_ids_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0mtrain_ndcgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-7a7107724006>\u001b[0m in \u001b[0;36m_calc_data_ndcg\u001b[0;34m(self, queries_list, true_labels, preds)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mquery_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquery_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mndcg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndcg_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndcg_top_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndcg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mndcg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-7a7107724006>\u001b[0m in \u001b[0;36m_ndcg_k\u001b[0;34m(self, ys_true, ys_pred, ndcg_top_k)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0mgain\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mideal_dcg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mpred_dcg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred_dcg\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mideal_dcg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-7a7107724006>\u001b[0m in \u001b[0;36mdcg\u001b[0;34m(ys_true, ys_pred)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mgain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_true_sorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0mgain\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mideal_dcg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def objective(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4, 1)\n",
        "    subsample = trial.suggest_float(\"subsample\", 0.0, 0.9999)\n",
        "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.0, 136/137)\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 20)\n",
        "    ndcg_top_k = 10\n",
        "    score = LambdaMART_10k(n_estimators, lr, ndcg_top_k, subsample, colsample_bytree, max_depth, min_samples_leaf).fit()\n",
        "    return score\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7G75omBl03lR"
      },
      "outputs": [],
      "source": [
        "LamdaMART = LambdaMART_10k(**{'n_estimators': 175,\n",
        "                         'lr': 0.6196291225251893, 'subsample': 0.918126554572848,\n",
        "                         'colsample_bytree': 0.9059311624006442, 'max_depth': 9,\n",
        "                         'min_samples_leaf': 19})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJRhDfVK14mN",
        "outputId": "648dd9c6-0c4c-4cf5-c7e6-cb2dc19a1180"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tree 0 ndcg@10: train = 0.5171892120577823, test = 0.3611031253398819\n",
            "Tree 1 ndcg@10: train = 0.583675035114946, test = 0.37856525739400904\n",
            "Tree 2 ndcg@10: train = 0.5953003118435541, test = 0.3900551534977488\n",
            "Tree 3 ndcg@10: train = 0.6175771463533928, test = 0.3989223285197196\n",
            "Tree 4 ndcg@10: train = 0.6345514850369816, test = 0.40670586967925454\n",
            "Tree 5 ndcg@10: train = 0.6516942923096405, test = 0.4032273869749836\n",
            "Tree 6 ndcg@10: train = 0.6619218892749699, test = 0.4136299703227864\n",
            "Tree 7 ndcg@10: train = 0.6736072596462294, test = 0.4077527990818701\n",
            "Tree 8 ndcg@10: train = 0.6768882798737493, test = 0.4009376762180843\n",
            "Tree 9 ndcg@10: train = 0.6803962834950151, test = 0.39886727471920574\n",
            "Tree 10 ndcg@10: train = 0.6851207206304046, test = 0.4018547725863755\n",
            "Tree 11 ndcg@10: train = 0.6813608205866539, test = 0.4033362406983294\n",
            "Tree 12 ndcg@10: train = 0.6981307069460551, test = 0.4066471269946884\n",
            "Tree 13 ndcg@10: train = 0.7060119314440365, test = 0.40756974017924885\n",
            "Tree 14 ndcg@10: train = 0.7139374442484187, test = 0.41239502623846586\n",
            "Tree 15 ndcg@10: train = 0.7146943434216511, test = 0.4102263155139305\n",
            "Tree 16 ndcg@10: train = 0.7183263346381571, test = 0.4042005149478262\n",
            "Tree 17 ndcg@10: train = 0.7245786467502857, test = 0.41076038587330416\n",
            "Tree 18 ndcg@10: train = 0.7299448929983994, test = 0.40817254375327716\n",
            "Tree 19 ndcg@10: train = 0.7315124314406822, test = 0.41492805731567467\n",
            "Tree 20 ndcg@10: train = 0.7394361208225119, test = 0.4176040103828365\n",
            "Tree 21 ndcg@10: train = 0.7401439568092083, test = 0.41789935444566334\n",
            "Tree 22 ndcg@10: train = 0.7442254776927246, test = 0.41828351273116743\n",
            "Tree 23 ndcg@10: train = 0.7486709205583594, test = 0.42001024151051586\n",
            "Tree 24 ndcg@10: train = 0.7524616156501331, test = 0.4216646606271917\n",
            "Tree 25 ndcg@10: train = 0.7497279013710461, test = 0.42312542272900994\n",
            "Tree 26 ndcg@10: train = 0.7512183127732113, test = 0.4240260132673112\n",
            "Tree 27 ndcg@10: train = 0.7559148634987316, test = 0.42124942216006195\n",
            "Tree 28 ndcg@10: train = 0.7587382553637713, test = 0.4254375025629997\n",
            "Tree 29 ndcg@10: train = 0.7664291200966671, test = 0.427826523992487\n",
            "Tree 30 ndcg@10: train = 0.7692221690868509, test = 0.4267297186465426\n",
            "Tree 31 ndcg@10: train = 0.7711142281006123, test = 0.4233532702042298\n",
            "Tree 32 ndcg@10: train = 0.7718697895948914, test = 0.4247215698811818\n",
            "Tree 33 ndcg@10: train = 0.7773079159616054, test = 0.42009376552463934\n",
            "Tree 34 ndcg@10: train = 0.7813354038644111, test = 0.42560847950252617\n",
            "Tree 35 ndcg@10: train = 0.7795783315581837, test = 0.42807524776170874\n",
            "Tree 36 ndcg@10: train = 0.7854243708753038, test = 0.4309334734200754\n",
            "Tree 37 ndcg@10: train = 0.7846535526472946, test = 0.4300669852051545\n",
            "Tree 38 ndcg@10: train = 0.786023940848208, test = 0.43216563464904373\n",
            "Tree 39 ndcg@10: train = 0.7878557299745494, test = 0.42911916924640536\n",
            "Tree 40 ndcg@10: train = 0.7908991684858826, test = 0.4294181008907882\n",
            "Tree 41 ndcg@10: train = 0.7913018869257521, test = 0.42831196111034264\n",
            "Tree 42 ndcg@10: train = 0.7908168304925678, test = 0.4248541486872868\n",
            "Tree 43 ndcg@10: train = 0.7910600003154798, test = 0.42546618391167035\n",
            "Tree 44 ndcg@10: train = 0.7933948245541803, test = 0.42715890976515686\n",
            "Tree 45 ndcg@10: train = 0.795354021006617, test = 0.42256665365262464\n",
            "Tree 46 ndcg@10: train = 0.7940999934043007, test = 0.4277665366587991\n",
            "Tree 47 ndcg@10: train = 0.7992520976340634, test = 0.42889362857253716\n",
            "Tree 48 ndcg@10: train = 0.7987702749241358, test = 0.42864488111808896\n",
            "Tree 49 ndcg@10: train = 0.802017901820698, test = 0.42789536917751486\n",
            "Tree 50 ndcg@10: train = 0.80120784249799, test = 0.4278510833497752\n",
            "Tree 51 ndcg@10: train = 0.8033901870935812, test = 0.42975200924345036\n",
            "Tree 52 ndcg@10: train = 0.8071071416482158, test = 0.42680319322442467\n",
            "Tree 53 ndcg@10: train = 0.8091368819105214, test = 0.42767257552424615\n",
            "Tree 54 ndcg@10: train = 0.8077971907867783, test = 0.42543345473876054\n",
            "Tree 55 ndcg@10: train = 0.8124180258005514, test = 0.4238446544093842\n",
            "Tree 56 ndcg@10: train = 0.8122958068189949, test = 0.42677734296938236\n",
            "Tree 57 ndcg@10: train = 0.8140097233070724, test = 0.42296104603023693\n",
            "Tree 58 ndcg@10: train = 0.8150888167578598, test = 0.4242965123108165\n",
            "Tree 59 ndcg@10: train = 0.8161643442066236, test = 0.42690953269431536\n",
            "Tree 60 ndcg@10: train = 0.815026176386866, test = 0.4257777659645812\n",
            "Tree 61 ndcg@10: train = 0.8175172161781925, test = 0.42612829749387776\n",
            "Tree 62 ndcg@10: train = 0.8155044817376411, test = 0.426526800009676\n",
            "Tree 63 ndcg@10: train = 0.8147516319121437, test = 0.42980701819231565\n",
            "Tree 64 ndcg@10: train = 0.816037742570899, test = 0.42779694637283683\n",
            "Tree 65 ndcg@10: train = 0.8179996321941244, test = 0.4273236350325698\n",
            "Tree 66 ndcg@10: train = 0.8197332243809755, test = 0.42741514374078676\n",
            "Tree 67 ndcg@10: train = 0.8192599648716806, test = 0.428215827496553\n",
            "Tree 68 ndcg@10: train = 0.8184129630012074, test = 0.42955536721274257\n",
            "Tree 69 ndcg@10: train = 0.8209024400546633, test = 0.431658836631951\n",
            "Tree 70 ndcg@10: train = 0.8224382592343736, test = 0.42997811594977975\n",
            "Tree 71 ndcg@10: train = 0.8232680209751787, test = 0.4273711350238459\n",
            "Tree 72 ndcg@10: train = 0.8257438334925421, test = 0.42869250260462816\n",
            "Tree 73 ndcg@10: train = 0.8263633833534416, test = 0.42953986348584294\n",
            "Tree 74 ndcg@10: train = 0.8257122176817093, test = 0.4303996733559126\n",
            "Tree 75 ndcg@10: train = 0.8266026076229139, test = 0.4288909221491353\n",
            "Tree 76 ndcg@10: train = 0.8270343644865628, test = 0.42981221404095943\n",
            "Tree 77 ndcg@10: train = 0.8287099318942804, test = 0.4324944074773653\n",
            "Tree 78 ndcg@10: train = 0.8311782472435085, test = 0.43147533636709506\n",
            "Tree 79 ndcg@10: train = 0.8303770916215305, test = 0.43222957815636287\n",
            "Tree 80 ndcg@10: train = 0.8307610373387392, test = 0.4321091664447026\n",
            "Tree 81 ndcg@10: train = 0.8326583518379036, test = 0.4278578923761167\n",
            "Tree 82 ndcg@10: train = 0.8371658160768706, test = 0.4254035984843292\n",
            "Tree 83 ndcg@10: train = 0.837938012747929, test = 0.4266427746465938\n",
            "Tree 84 ndcg@10: train = 0.8388595437181408, test = 0.42676845675503666\n",
            "Tree 85 ndcg@10: train = 0.84005257041975, test = 0.4271639341657812\n",
            "Tree 86 ndcg@10: train = 0.8396099333105416, test = 0.4264597313224592\n",
            "Tree 87 ndcg@10: train = 0.8418738691286108, test = 0.42419254792515526\n",
            "Tree 88 ndcg@10: train = 0.8450579252736322, test = 0.42653866099532356\n",
            "Tree 89 ndcg@10: train = 0.8451795639662907, test = 0.426840023687956\n",
            "Tree 90 ndcg@10: train = 0.8472245212258964, test = 0.4253655043853955\n",
            "Tree 91 ndcg@10: train = 0.8469532748748516, test = 0.4272580736062743\n",
            "Tree 92 ndcg@10: train = 0.8482449397273447, test = 0.4253060613674196\n",
            "Tree 93 ndcg@10: train = 0.8489731440598938, test = 0.4253279250961813\n",
            "Tree 94 ndcg@10: train = 0.8503443208234064, test = 0.4263285197825594\n",
            "Tree 95 ndcg@10: train = 0.8518508405520998, test = 0.42295669188553636\n",
            "Tree 96 ndcg@10: train = 0.8520381539717488, test = 0.4230164208195426\n",
            "Tree 97 ndcg@10: train = 0.8515275326268427, test = 0.42446721565317025\n",
            "Tree 98 ndcg@10: train = 0.8514461065160817, test = 0.42556394314901397\n",
            "Tree 99 ndcg@10: train = 0.8523694098680868, test = 0.4252650380473245\n",
            "Tree 100 ndcg@10: train = 0.8520078008202301, test = 0.42098552225665614\n",
            "Tree 101 ndcg@10: train = 0.8533808177915113, test = 0.4260477995161306\n",
            "Tree 102 ndcg@10: train = 0.8526096419356335, test = 0.42361910234798084\n",
            "Tree 103 ndcg@10: train = 0.8541592585629431, test = 0.42609269883144985\n",
            "Tree 104 ndcg@10: train = 0.8523897768437178, test = 0.4278195800090378\n",
            "Tree 105 ndcg@10: train = 0.8538132981322277, test = 0.4262079761617563\n",
            "Tree 106 ndcg@10: train = 0.8535926835290317, test = 0.4280538073402237\n",
            "Tree 107 ndcg@10: train = 0.8567430212579924, test = 0.42666958492587914\n",
            "Tree 108 ndcg@10: train = 0.858376535190933, test = 0.42504204280505126\n",
            "Tree 109 ndcg@10: train = 0.8600577753165672, test = 0.42744541265578434\n",
            "Tree 110 ndcg@10: train = 0.8607233653123352, test = 0.42857333420860494\n",
            "Tree 111 ndcg@10: train = 0.8618116241762008, test = 0.42788250105116854\n",
            "Tree 112 ndcg@10: train = 0.8619187385186382, test = 0.4275193846022541\n",
            "Tree 113 ndcg@10: train = 0.8616348696851183, test = 0.42787719259715895\n",
            "Tree 114 ndcg@10: train = 0.8618546491381766, test = 0.42814629791643133\n",
            "Tree 115 ndcg@10: train = 0.8630649961274246, test = 0.4296183165332133\n",
            "Tree 116 ndcg@10: train = 0.8620022137959799, test = 0.4323228077793663\n",
            "Tree 117 ndcg@10: train = 0.8621522756828659, test = 0.43222983994267206\n",
            "Tree 118 ndcg@10: train = 0.8636482042827826, test = 0.4305431478318166\n",
            "Tree 119 ndcg@10: train = 0.8638434348435238, test = 0.42853751859035005\n",
            "Tree 120 ndcg@10: train = 0.865309954374686, test = 0.426930113653229\n",
            "Tree 121 ndcg@10: train = 0.8665869530590101, test = 0.4286921180530705\n",
            "Tree 122 ndcg@10: train = 0.8655934738016676, test = 0.428361072755334\n",
            "Tree 123 ndcg@10: train = 0.868519463758359, test = 0.4299513248896057\n",
            "Tree 124 ndcg@10: train = 0.8677319576000345, test = 0.42941772141917184\n",
            "Tree 125 ndcg@10: train = 0.8666015630480887, test = 0.42953669923273\n",
            "Tree 126 ndcg@10: train = 0.8678084146017315, test = 0.4276545379649509\n",
            "Tree 127 ndcg@10: train = 0.8696368960128433, test = 0.42887811168012296\n",
            "Tree 128 ndcg@10: train = 0.8689492098216353, test = 0.42588991760699585\n",
            "Tree 129 ndcg@10: train = 0.8701693696537237, test = 0.42685578733851964\n",
            "Tree 130 ndcg@10: train = 0.8695676456922772, test = 0.4270181591961194\n",
            "Tree 131 ndcg@10: train = 0.8706818880705998, test = 0.42788734574886883\n",
            "Tree 132 ndcg@10: train = 0.869860306553457, test = 0.4272825352170251\n",
            "Tree 133 ndcg@10: train = 0.8704161191808766, test = 0.4279129598289728\n",
            "Tree 134 ndcg@10: train = 0.8692144868017613, test = 0.42918210629035125\n",
            "Tree 135 ndcg@10: train = 0.8686952721113446, test = 0.4264041567221284\n",
            "Tree 136 ndcg@10: train = 0.868640193308907, test = 0.4286046735095707\n",
            "Tree 137 ndcg@10: train = 0.8689837407791752, test = 0.42844301800836215\n",
            "Tree 138 ndcg@10: train = 0.8690287847628538, test = 0.4275157803838903\n",
            "Tree 139 ndcg@10: train = 0.869511248736546, test = 0.4279380541040816\n",
            "Tree 140 ndcg@10: train = 0.8694408405786274, test = 0.4246942613866519\n",
            "Tree 141 ndcg@10: train = 0.8697425449031523, test = 0.42509635465896944\n",
            "Tree 142 ndcg@10: train = 0.8695408236021283, test = 0.4247425470755182\n",
            "Tree 143 ndcg@10: train = 0.8700501829728313, test = 0.4246487214483998\n",
            "Tree 144 ndcg@10: train = 0.8706680865123354, test = 0.42489753367209976\n",
            "Tree 145 ndcg@10: train = 0.8705491526373501, test = 0.4255676022307439\n",
            "Tree 146 ndcg@10: train = 0.8708448862207347, test = 0.4274997138841586\n",
            "Tree 147 ndcg@10: train = 0.8718315883614551, test = 0.4274347930807959\n",
            "Tree 148 ndcg@10: train = 0.8710181096504475, test = 0.42698505673218856\n",
            "Tree 149 ndcg@10: train = 0.872827742291593, test = 0.42583118290217087\n",
            "Tree 150 ndcg@10: train = 0.8733335349751615, test = 0.42556398510086263\n",
            "Tree 151 ndcg@10: train = 0.8722783984809086, test = 0.4258332238109274\n",
            "Tree 152 ndcg@10: train = 0.8719444281753452, test = 0.42687789003618737\n",
            "Tree 153 ndcg@10: train = 0.8718684610279127, test = 0.4317008839412169\n",
            "Tree 154 ndcg@10: train = 0.8734437419080187, test = 0.42999423532323405\n",
            "Tree 155 ndcg@10: train = 0.8739538706582168, test = 0.4297539350492033\n",
            "Tree 156 ndcg@10: train = 0.8743133428453029, test = 0.42959188847717916\n",
            "Tree 157 ndcg@10: train = 0.8741614544528654, test = 0.42783388851041143\n",
            "Tree 158 ndcg@10: train = 0.873110523854179, test = 0.4231263798746196\n",
            "Tree 159 ndcg@10: train = 0.8746152568137509, test = 0.42381603008305485\n",
            "Tree 160 ndcg@10: train = 0.8746741078365808, test = 0.42313386664979835\n",
            "Tree 161 ndcg@10: train = 0.8762311476400528, test = 0.42356252699921076\n",
            "Tree 162 ndcg@10: train = 0.8759577171555881, test = 0.4232613543810492\n",
            "Tree 163 ndcg@10: train = 0.8750841850521921, test = 0.4237824222072959\n",
            "Tree 164 ndcg@10: train = 0.8753333543909008, test = 0.424509555016729\n",
            "Tree 165 ndcg@10: train = 0.8765944516521761, test = 0.4235909540968185\n",
            "Tree 166 ndcg@10: train = 0.8762030807034723, test = 0.42473395342345943\n",
            "Tree 167 ndcg@10: train = 0.8755650417558078, test = 0.4242167810655453\n",
            "Tree 168 ndcg@10: train = 0.8761369990206312, test = 0.42385490670461545\n",
            "Tree 169 ndcg@10: train = 0.8770617568629911, test = 0.42640186405994673\n",
            "Tree 170 ndcg@10: train = 0.8788286920251518, test = 0.42746996134519577\n",
            "Tree 171 ndcg@10: train = 0.8784184366807171, test = 0.42623139765452256\n",
            "Tree 172 ndcg@10: train = 0.8781478261125499, test = 0.42601664876565337\n",
            "Tree 173 ndcg@10: train = 0.8789933310157951, test = 0.42400652610442857\n",
            "Tree 174 ndcg@10: train = 0.8805765749394209, test = 0.42480779358778487\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.4324944074773653"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGeCAYAAABGlgGHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABZPElEQVR4nO3deXwU9f3H8ddujs2dEHKHQLgPOeUIhwdKFNSi4kWplUPFavFo0Z9IVfCoYrWl2NZKa0Xrbb21KhYQVK6AHHIIgXAlQE5C7mOT3fn9MSQQEyCBJEOS9/Px2AcwO7P7mdlh573f+c53bIZhGIiIiIhYxG51ASIiItK2KYyIiIiIpRRGRERExFIKIyIiImIphRERERGxlMKIiIiIWEphRERERCylMCIiIiKWUhgRERERS3laXUB9uN1uDh8+TGBgIDabzepyREREpB4Mw6CwsJCYmBjs9lO0fxhn4G9/+5vRqVMnw+FwGMOGDTOSkpJOOq/T6TQef/xxo0uXLobD4TD69+9vfPnllw16v7S0NAPQQw899NBDDz1a4CMtLe2Ux/kGt4y8++67zJw5k4ULF5KQkMCCBQsYO3YsycnJRERE1Jr/kUce4Y033uCll16iV69efPXVV0yYMIHVq1czaNCger1nYGAgAGlpaQQFBTW0ZBEREbFAQUEBcXFx1cfxk7EZRsNulJeQkMDQoUP529/+BpinUOLi4rjnnnt46KGHas0fExPDww8/zIwZM6qnXX/99fj6+vLGG2/U6z0LCgoIDg4mPz9fYURERKSFqO/xu0EdWJ1OJxs2bCAxMfH4C9jtJCYmsmbNmjqXKS8vx8fHp8Y0X19fVq5cedL3KS8vp6CgoMZDREREWqcGhZGcnBxcLheRkZE1pkdGRpKRkVHnMmPHjmX+/Pns3r0bt9vNkiVL+PDDD0lPTz/p+8ybN4/g4ODqR1xcXEPKFBERkRakyS/tff755+nevTu9evXC29ubu+++m2nTpp2yV+3s2bPJz8+vfqSlpTV1mSIiImKRBnVgDQsLw8PDg8zMzBrTMzMziYqKqnOZ8PBwPv74Y8rKyjhy5AgxMTE89NBDdOnS5aTv43A4cDgcDSkNl8tFRUVFg5aRlsXLywsPDw+ryxARkUbWoDDi7e3N4MGDWbZsGddeey1gdmBdtmwZd9999ymX9fHxITY2loqKCj744ANuuummMy76p4qKijh48CAN7IsrLYzNZqNDhw4EBARYXYqIiDSiBl/aO3PmTKZMmcKQIUMYNmwYCxYsoLi4mGnTpgEwefJkYmNjmTdvHgBJSUkcOnSIgQMHcujQIR577DHcbjcPPvhgo6yAy+Xi4MGD+Pn5ER4erkHRWinDMMjOzubgwYN0795dLSQiIq1Ig8PIxIkTyc7OZs6cOWRkZDBw4EAWL15c3ak1NTW1Rn+QsrIyHnnkEfbu3UtAQABXXnklr7/+OiEhIY2yAhUVFRiGQXh4OL6+vo3ymnJuCg8PZ//+/VRUVCiMiIi0Ig0eZ8QKp7pOuaysjH379tG5c+dalxBL66LPWkSkZWmScUZEREREGpvCiIiIiFhKYaQViI+PZ8GCBZbW8NhjjzFw4EBLaxARkZapwR1YpXGMHj2agQMHNkqIWL9+Pf7+/mdflIiIiAXUMnKOMgyDysrKes0bHh6On59fE1ckIiKtTYmzkv98n8bt//6eSpfbsjpaXRgxDIMSZ6Ulj/pemDR16lS++eYbnn/+eWw2GzabjVdffRWbzcaXX37J4MGDcTgcrFy5kj179nDNNdcQGRlJQEAAQ4cOZenSpTVe76enaWw2G//617+YMGECfn5+dO/enU8//bReta1YsQKbzcayZcsYMmQIfn5+jBw5kuTk5BrzPfPMM0RGRhIYGMhtt91GWVlZrddatGgR5513Hg6Hg+jo6BoD4+3cuZMLLrgAHx8f+vTpw9KlS7HZbHz88cf1qlNERE6urMLFpz8c5j/r01i2I5PNaXmk5ZZQ4qwkLbeE/245zO8+2krCU8t48P0tLN2RyfLkbMvqbXWnaUorXPSZ85Ul7/3jE2Px8z79Jn3++efZtWsXffv25YknngBg+/btADz00EP88Y9/pEuXLrRr1460tDSuvPJKnnrqKRwOB6+99hrjx48nOTmZjh07nvQ9Hn/8cZ599lmee+45/vrXv3LzzTdz4MABQkND67UuDz/8MH/6058IDw/nzjvv5NZbb2XVqlUA/Oc//+Gxxx7jhRde4IILLuD111/nL3/5S40h/l988UVmzpzJM888wxVXXEF+fn718i6Xi2uvvZaOHTuSlJREYWEh999/f73qEhGRuhmGwZ7sYj7edIg3kw5wtKR+t0jp1N6PiUPjGBgX0rQFnkKrCyMtQXBwMN7e3vj5+VXf02fnzp0APPHEE1x22WXV84aGhjJgwIDqfz/55JN89NFHfPrpp6ccgn/q1KlMmjQJgKeffpq//OUvrFu3jnHjxtWrxqeeeoqLL74YMAPSVVddRVlZGT4+PixYsIDbbruN2267DYDf//73LF26tEbryO9//3vuv/9+7rvvvuppQ4cOBWDJkiXs2bOHFStWVK//U089VWO9RURasyNF5Xy48RDf7s7Gx8uDYF8vYoJ9GNgxhP4dQvCy2ykoqyA5o5CvtmewPDkLZ6WbiCAfooJ86BzmT9dwf7w87ezPKWZPdjGbUo/WCCAd2vnSLSKAI0VOcoudZBeV46x04+Vho3d0EAM6hHBF3yiGd2mP3W7t6OWtLoz4ennw4xNjLXvvszVkyJAa/y4qKuKxxx7j888/Jz09ncrKSkpLS0lNTT3l6/Tv37/67/7+/gQFBZGVlVXvOk5cPjo6GoCsrCw6duzIjh07uPPOO2vMP2LECJYvX1493+HDhxkzZkydr52cnExcXFyNmysOGzas3rWJiFjN7TbILXGSkV9GRn4Z6QVl5BSW4+Vhw8fLg4ggH4Z3CSUi0IdDeaV8tPEgGw4cpdJtUFbhYnNaHhWuho85WlBWREpWEStTcup83uFpZ0h8O36Z0InL+kTi6XG8N4ZhGBQ7XXh52HB4nlujWLe6MGKz2ep1quRc9dOrYh544AGWLFnCH//4R7p164avry833HADTqfzlK/j5eVV4982mw23u/6dk05cvup+P/VdXsPyi0hLYBgGa/Ye4X/bM0nNLeHg0RICHJ6M7BrGyK7tiQv1o32Ad/UxpdLlZnlyNu+sS+W7lByclaf/TowL9eXg0VLq6lI4oEMw1w6KxdvTTl5JBftyzNaNPdnFAPh42YkM8uGSnhFc3ieSiCAHmQXlHM4rZW9OMSlZRbjcBp3a+9E5zJ9+scGcFxOMt2fd3UFtNhsBjnPz+HhuVtUGeHt743K5TjvfqlWrmDp1KhMmTADMlpL9+/c3cXWn1rt3b5KSkpg8eXL1tLVr11b/PTAwkPj4eJYtW8Yll1xSa/mePXuSlpZGZmZm9T2N1q9f3/SFi0iTySwoI8Dhib+FB7sSZyWZBeV42m04PO1UuA2OFjvJKizj+/1HSdqXy5GicvrEBNE9IpBlOzPZdqig1utsTM3jb8tTqv/tabfh5WHHwKCsomYACQtwEB3sQ1SwD2EBDtxug9IKF3uyi/gxvYC03FIAhncJ5cp+0QT5eGG32+gZGUjPqMA616PU6cLDbqszVHSLqHuZlk5hxCLx8fEkJSWxf/9+AgICTtrq0L17dz788EPGjx+PzWbj0UcfbVALR1O47777mDp1KkOGDGHUqFG8+eabbN++vUYH1scee4w777yTiIgIrrjiCgoLC1m1ahX33HMPl112GV27dmXKlCk8++yzFBYW8sgjjwDorssi55Bth/JJ2pdLh3a+9IgMJD2/lKU/ZvH9gVza+3vTJTwAZ6Wbb3dnc+BICXYbdIsIoGOoP4fzSknLLaGdvzeX9org0l4R9IwKJDzAUat/QqXLTVF5JS63gcswOFLk5NDRUrKLyrEBHnYbTpebvJIK8ksr8PKw4e/wxDDgwJFi9h8p4cCRYjILyuu1XvuPlAAZgNn6MGFQLP1iQ4ht50tWQRmrUnL4/sBRsgrNPhaVboNKt/njsb2/N9cP7sB158fSJSzgpK0QAEeLnfxwMI+u4QHEhdZ/+AVf73PrFEpzUBixyAMPPMCUKVPo06cPpaWlvPLKK3XON3/+fG699VZGjhxJWFgYs2bNoqCgdpJvThMnTmTPnj08+OCDlJWVcf3113PXXXfx1VfHr2KaMmUKZWVl/PnPf+aBBx4gLCyMG264AQAPDw8+/vhjbr/9doYOHUqXLl147rnnGD9+vG6AJ9LECssqeH7pblJzS+gTE0S/2GCGxIcS7GuemnVWuvludzYvr9zH6j1HTvlaJ14KarOB24BdmUXsyiw6/n7llby6ej+vrt4PmH0awgIceNht2G1QUFbJ0RJnnacxzoS/twduA8orzdaFED9vQv28OS82iOGd2xMd4sOPhwvYmVFIt4gAfjGsI+38vWu8xo1D4oDjfSwKyyqodBm43AYxIb6nDCAnaufvzeieEY2zYq2c7tor54RVq1ZxwQUXkJKSQteuXeucR5+1SMPsyylmRXIW/t6eJHQJJa+kgnve3kRqbkmN+TzsNs7vGEJ7fwcrU3IoKq+snn5BtzCOFJezO7MIf4cnl/aK4MLuYRSVV7I3uxi3YTCyaxgjuranpLySLQfzOZxfSkywLx3b+7E/p5hlO7JYvTeHQ0dLcZ/miGOzQYivF7HtfIkK8gFsVLrdeNrttPPzItjXi0q3QVF5JYYBHUP9iA/zI769P53a+xHiZwaLqkObWlutVd+79qplRCzx0UcfERAQQPfu3UlJSeG+++5j1KhRJw0iIlI/abklfLTpEJ9vSSc5s7DOeWJDfPnl8E7szipkc2oee3OKWb//aPXzYQEOrhkYw60XdCY2xOyQ7nYb2GynPrgHODxJ7FPzh0KPyEAuP8+8cq7C5SY9r4zcEicut4HbMAjy8aJ9gDfBvl542m2NFh4UQloWhZE25s477+SNN96o87lf/vKXLFy4sFnqKCwsZNasWaSmphIWFkZiYiJ/+tOfmuW9RVqS/JIK0gtK6RYeUOMyTYBDeaV8vOkQuzMLKXa6yCos54e0vOrnPe02hndpT1mFix8OmpeSXtE3imeu60+w3/Er5tJyS/h2dzZHi51c0D2c/rHBtfp1NMY4FF4edjq296Nje92+QmrSaZo2Jisr66R9ToKCgoiIOHfPb+qzltYiu7CcNXuPkFVQRnmlG5fbINDHkxA/L7w87BSVVXKk2Mm3u7L5/sBR83mHJ8O7tic62IeyChepuSUk7cut1dfCZoNRXcO4dlAsl/WOrA4dpU4XeaVOooJ81GogzUanaaROERER53TgEGlt3G6Ddftz2X64gJSsQjan5bMjvWGd0H29PCgsr2TJj5m1nhveJZTRPSMI8vEiwMeTofHtiA6uPdaPr7cHvt4aA0jOTQojIiJNILfYyXvfp/FmUmqtDqMA58UE0T3CvDTUbrNRWF5JfkkFFS43gT6eBDg8GRAXQmLvSGJCfNl+OJ/Ve45QUl6Jw8uDIB9PRveMaNAloyLnKoUREZFGtCn1KK+vPcB/t6RXj9AZ6OPJyK7t6XFsoKvhXdoTFuBo0Ov272Des0SkNVIYERFpBGUVLuZ+sp13v0+rntY3Nohbhndi/ICYFn2bCpGmpv8dIiKn4HIbfLc7m6MlThJ7RxLoY3YILSqvZGd6AT5eHhgGPPzxVrYczMdug2sHxTJ5RDwDOgSrs6hIPSiMiEirYxjmPUSKnZV4e9oJ8vGqNU9BWQVbD+ZjGBAW6E2ly+DLbel8uTWDYmclfaKDiG3ny9Ifs8goKAMg0OHJ9YM7kFNUztIdmbXuU9LOz4u/TBrEhd3Dm2U9RVoLhRFpkFdffZXf/OY35OXlWV2KSA0lTvNqk483HWJlSk6N27MH+3oRG+KLv8MDLw87ucVOkjMLTzkEeWbB8aHO2/l5EeLnzb6c4uphzQEig8x+H0VllfTrEMwfbxxAh3bqUCrSUAojFhk9ejQDBw5kwYIFjfJ6U6dOJS8vj48//rhRXk+kJXBWulm79wgfbzrE4u0ZlDjrvhN2fql5g7Wfigv1xdfLg5wiJ2UVLi7oFsb4ATHEhPiw/XAB+3NKGNypHYl9IvCy2/lmdzYfbzpUPUJpv1idhhFpDAojItJiFJdX8s2ubJbtyGL74XxSsoqoPOFmJx1D/bh2UCzj+0cTE2IGjdIKFwePlnI4r5SyChcVbgOHp51BcSFEBJ188LzBnUJrTbukZwSX6MZnIo2ufrcebEkMA5zF1jzqOZjt1KlT+eabb3j++eex2cx7Mezfv59t27ZxxRVXEBAQQGRkJLfccgs5OTnVy73//vv069cPX19f2rdvT2JiIsXFxTz22GP8+9//5pNPPql+vRUrVpyyhv3792Oz2fjwww+55JJL8PPzY8CAAaxZs6bGfK+++iodO3bEz8+PCRMmcORI7bt4fvbZZwwdOhQfHx/CwsKYMGFC9XPp6elcddVV+Pr60rlzZ9566y3i4+MbrUVIWq+03BIefP8H+sxZzIDH/8dFzy7n/CeX8Os3N/LBxoPszCik0m0Q6u/NLcM78cFdI/nm/0Yz87IedI8MxN/hid1u3mq+Z1Qgl/SK4Ip+0Vw9IIax50WdMoiISPNqfS0jFSXwdIw17/27w+Dtf9rZnn/+eXbt2kXfvn154oknAPDy8mLYsGHcfvvt/PnPf6a0tJRZs2Zx00038fXXX5Oens6kSZN49tlnmTBhAoWFhXz33XcYhsEDDzzAjh07KCgo4JVXXgEgNLT2r7q6PPzww/zxj3+ke/fuPPzww0yaNImUlBQ8PT1JSkritttuY968eVx77bUsXryYuXPn1lj+888/Z8KECTz88MO89tprOJ1Ovvjii+rnJ0+eTE5ODitWrMDLy4uZM2eSlZVV3y0qbcj3+3P5ePMhSpwuCkorWZGcdUKrh6v6NEtcqC9X9I0moXMovaKDiAnW8OYiLV3rCyMtQHBwMN7e3vj5+REVZd7N8ve//z2DBg3i6aefrp5v0aJFxMXFsWvXLoqKiqisrOS6666jU6dOAPTr1696Xl9fX8rLy6tfr74eeOABrrrqKgAef/xxzjvvPFJSUujVqxfPP/8848aN48EHHwSgR48erF69msWLF1cv/9RTT/Hzn/+cxx9/vHragAEDANi5cydLly5l/fr1DBkyBIB//etfdO/evUE1SutmGAYvr9zHvC934vrJ/eUv7B7G3Zd0o32AN3klFQT6eNEjMkDhQ6SVaX1hxMvPbKGw6r3P0A8//MDy5csJCAio9dyePXu4/PLLGTNmDP369WPs2LFcfvnl3HDDDbRr1+5sKqZ///7Vf4+OjgbMm+n16tWLHTt21DjlAjBixIgaYWTz5s1Mnz69ztdOTk7G09OT888/v3pat27dzrpmaT3ySpzM+WQ7n/5g/p+9sl8UAzqE4O1pp3+HEAZ30r4i0ha0vjBis9XrVMm5pqioiPHjx/OHP/yh1nPR0dF4eHiwZMkSVq9ezf/+9z/++te/8vDDD5OUlETnzp3P+H29vI6Pv1D1a9Ptdp9s9lp8fXXjLamfrIIyNqbmEeTjSVSwDyuSs3l+2W7ySyvwsNt49KreTBkZr1YPkTao9YWRFsLb2xuX6/hliOeffz4ffPAB8fHxeHrW/bHYbDZGjRrFqFGjmDNnDp06deKjjz5i5syZtV6vMfTu3ZukpKQa09auXVvj3/3792fZsmVMmzat1vI9e/aksrKSTZs2MXjwYABSUlI4evRoo9Yp56bswnJ+SMtjc1oe3+7OZsvB/Drn6xUVyJPX9mVofP36OYlI66MwYpH4+HiSkpLYv38/AQEBzJgxg5deeolJkybx4IMPEhoaSkpKCu+88w7/+te/+P7771m2bBmXX345ERERJCUlkZ2dTe/evatf76uvviI5OZn27dsTHBxco9XjTNx7772MGjWKP/7xj1xzzTV89dVXNU7RAMydO5cxY8bQtWtXfv7zn1NZWckXX3zBrFmz6NWrF4mJidxxxx28+OKLeHl5cf/99+Pr66tfv62Qy23wzvpUVqXk8ENaPofySmvN0ysqEKfLTXpeGcG+Xtw7pjsTh8bhYdf+INKWKYxY5IEHHmDKlCn06dOH0tJS9u3bx6pVq5g1axaXX3455eXldOrUiXHjxmG32wkKCuLbb79lwYIFFBQU0KlTJ/70pz9xxRVXADB9+nRWrFjBkCFDKCoqYvny5YwePfqsahw+fDgvvfQSc+fOZc6cOSQmJvLII4/w5JNPVs8zevRo3nvvPZ588kmeeeYZgoKCuOiii6qff+2117jtttu46KKLiIqKYt68eWzfvh0fH11W2ZoYhsFjn27n9bUHqqfZbNA9IoABHUIYGh/K6F7hRAT6VM9vzqMQIiJgM4x6Do5hoYKCAoKDg8nPzycoKKjGc2VlZezbt4/OnTvrANcCHDx4kLi4OJYuXcqYMWMatKw+63PX31ek8OziZGw2uPuSbozo2p5+scHVN5UTkbbpVMfvE6llRJrU119/TVFREf369SM9PZ0HH3yQ+Pj4Gq0n0nJVuNy8tuYAzy5OBmDOz/owbdSZd6gWkbZJYaSVevrpp2uMWXKiCy+8kC+//LJZ6qioqOB3v/sde/fuJTAwkJEjR/Lmm2+edX8WaT5Je4+wdEcmcaF+9I0NJtjXi+zCcn48XMDLK/dV9w2546IuCiIickYURlqpO++8k5tuuqnO55rzctyxY8cyduzYZns/aTxHisp5+oudfLDx4CnnCwvw5o6LunD7BV2aqTIRaW0URlqp0NDQeg8JL3KivdlFvLE2lfc2pFFYVonNBlf2i6a4vJJth/Ipq3ATEeggMsiHK/pFcdOQOHy8PKwuW0RasFYTRlpAP1w5S/qMz1xxeSW7MgvZm11MZmEZHdr50S08AKfLzcYDR9l6KJ9DR0vJKCgjNbekerne0UE8NaEv53fUSKgi0nRafBjx8DB/kTmdTo0G2so5nU7g+Gcup1fhcvPqqv0sWLqLYmf9BsWz2eCSnhHcMqITF3cPx64xQESkibX4MOLp6Ymfnx/Z2dl4eXlht9utLkmagNvtJjs7Gz8/v5OOUCsmt9tgb04xP6Tl8dJ3e9mZUQhAWICD7hEBRAY5SDtaSkpWEXYbDOrYjoFxIXQO8ycq2IdO7f2qxwMREWkOLf5b3WazER0dzb59+zhw4MDpF5AWy26307FjRw2UVQfDMNhyMJ//fJ/Gf7ekk19aUf1ciJ8Xv7uiNzcM7qBWDhE5J7X4MALmfV66d+9e3YwvrZO3t3ebbfkqq3Bx4EgJ4YEO2vl51Qhk2w7l8+gn29iUmlc9zcfLTt+YYIbEh3LHRV0I9fe2oGoRkfppFWEEzF/NGpVTWpvDeaW8vvYAb69LJa/EbO3w8bLT7dgw6wBvr0vFbYDD0864vlHcODiO4V1C8fRom8FNRFqeVhNGRFqCymMjln63O5uJQ+O4vE9UnadO9ucU88LyFD7adIhKt3kVkZ+3ByVOF2UVbrYdKmDboYLq+X/WP5pHf9aHyCAFchFpeRRGRBpZhcvNloN5fLc7h1UpORSUVjKia3sGxoXw0nd72X7YDBHLk7PpHR3EL4d3pF9sMNHBvqxKyeGLreks3ZHJsQzC8C6hTBvVmcTekVS43KTnl7EjvYAf0vJIzy/juvNjGd0zwsI1FhE5Oy3+Rnki54ISZyWf/XCYJT9msXbvEYrKK086b7CvF1f2i+azHw6fcr5Le0Vwz6XdGKQxPkSkhdKN8kSaiNttsHh7Bqm5JTg87Rw6Wsp7Gw7WuoJlVNcwRnULI8TPi+92Z7PhwFEGdAhh1hW9CAtwMGtcT15fc4CkfblsP5zP0ZIKukUEMO68KH42IJpeUQreItI2qGVEpIH+sHgnL67YU2t6x1A/bhrSgYt6hHNeTDAeDbiM1jAMip0uAhz6fSAirYdaRkQaQVmFi+/3HyU+zI8O7fx4Kym1Oohc2S8Ku82Gp93G+AExjO4Z0aAAciKbzaYgIiJtlr79ROpQXuniP+vTeGH5HjIKygDoFxvMj+lm59PfJvbgvsTuVpYoItJqKIyI/ERabglTXlnH3uxiwOz/kV9awdZD+QBcf34H7h3TzcoSRURaFYURkRPszizkly8nkVlQTliAg3vHdGPi0DjySyv4alsGBWWVTL+wi4akFxFpRGc0ROMLL7xAfHw8Pj4+JCQksG7dulPOv2DBAnr27Imvry9xcXH89re/pays7IwKFmkKhmGwPDmLG/+xhsyCcrpHBPDfey5g8oh4HJ4eRAT6cMuIeGZc0g1vT41sKiLSmBrcMvLuu+8yc+ZMFi5cSEJCAgsWLGDs2LEkJycTEVF74KW33nqLhx56iEWLFjFy5Eh27drF1KlTsdlszJ8/v1FWQqQhDMPgrXWpfLcrh64R/nSLCOD9DQdZlXIEgAFxIbw6dSjtdD8XEZFm0eBLexMSEhg6dCh/+9vfAPPW7nFxcdxzzz089NBDtea/++672bFjB8uWLauedv/995OUlMTKlSvr9Z66tFcaS1mFi9kfbuWjTYdqPeftYWfyiE789rIe+OvKFhGRs9Ykl/Y6nU42bNjA7Nmzq6fZ7XYSExNZs2ZNncuMHDmSN954g3Xr1jFs2DD27t3LF198wS233HLS9ykvL6e8vLzGyoicifJKF3e+voEtB/OJDvGhpNzF3pxiPOw2brugMwWlFezIKKR7RAD3jelOXKif1SWLiLQ5DQojOTk5uFwuIiMja0yPjIxk586ddS7zi1/8gpycHC644AIMw6CyspI777yT3/3udyd9n3nz5vH44483pDSROj353x9ZnpwNwJFiJwDt/Lx44RfnM7JbmJWliYjIMU3eFr1ixQqefvpp/v73v5OQkEBKSgr33XcfTz75JI8++midy8yePZuZM2dW/7ugoIC4uLimLlVauAqXm+U7s/D0sDGyaxhfbE3njbWpADx3Q3/a+XmTW+Lk4h7hurutiMg5pEFhJCwsDA8PDzIzM2tMz8zMJCoqqs5lHn30UW655RZuv/12APr160dxcTF33HEHDz/8MHZ77SsTHA4HDoejIaVJG+asdPPBxoO8sDyFg0dLAfDz9qDy2G1v7x3TnRuHKMyKiJyrGnSNore3N4MHD67RGdXtdrNs2TJGjBhR5zIlJSW1AoeHhwdgXtUgcqYMw2Dpj5lc/udvmP3hVg4eLSUswJuYYB9KnC6clW4u6hHOfWM0UqqIyLmswadpZs6cyZQpUxgyZAjDhg1jwYIFFBcXM23aNAAmT55MbGws8+bNA2D8+PHMnz+fQYMGVZ+mefTRRxk/fnx1KBH5KZfbvPx2c2oeWYVlHC1xEhbgICbEl0CHJwVllezJLmLdvlwAwgMd3HVxVyYN64iPl53thwvYfjifn/WPOeP7xYiISPNocBiZOHEi2dnZzJkzh4yMDAYOHMjixYurO7WmpqbWaAl55JFHsNlsPPLIIxw6dIjw8HDGjx/PU0891XhrIa1KdmE5972zidV7jpx2Xm8PO7de0Jm7L+1W40ZzfWOD6Rsb3JRliohII2nwOCNW0DgjbYPLbfC/7RnM/XQ7WYXl+Hl7cPuFXegU6keInxfZheUcyiulxOkiyMeLYF9PLukVQaf2/laXLiIidWiScUZEmkJeiZPPtqSzaOU+9uWYN6frHhHAi788n24RgRZXJyIiTU1hRJrV4m3p/ObdzUQG+XBeTBBlFW6+251NhctsoAvy8WTyiHh+fUlX/Ly1e4qItAX6tpdmk5FfxoPvb6Gsws2BIyUcOFJS/VyvqEBuGhLHxKFxGopdRKSN0be+NJn80grW7ctlZNf2+Hl7MOuDLRSUVdK/QzAPju3F9sP5VLoNLu8TSfdInY4REWmrFEakSWQVljHpn2vZk11MkI8nwzq355td2Xh72pl/0wC6RQRyQXcNxy4iIg0c9EykPrILy/nFS0nsyS7GboOCskqW7jBH7X1wbE91ShURkRrUMiKNKr+kgl+8tJaUrCKignx4+47h7M0u4q2kVCKDfbh1VGerSxQRkXOMwog0GsMwePCDH9h9LIi8c8dw4sP86Rzmz5jekad/ARERaZN0mkYazRtrD/DV9ky8PGz8c/Jg4sM0GJmIiJyeWkbkrLndBhtSj/Lk5zsAeOiK3vTvEGJtUSIi0mIojMgZqXS5+e+WdN5al8r2Q/kUO10AJPaO4NZR8dYWJyIiLYrCiDSIYRi89/1B/rp8N2m5pdXTHZ52RnRtz3M3DMBm011yRUSk/hRGpN4yC8r4v/e38O2ubADa+3szbVQ8l58XRZcwfzw91AVJREQaTmFE6mX9/lymv/Y9eSUVODztzLysB5NHxOPr7WF1aSIi0sIpjMhpVbrczPpgC3klFZwXE8SCiQM1fLuIiDQahRE5rQ83HWJvdjHt/Lx4547hBPp4WV2SiIi0IjrJL6dUXuni+aW7AbhrdFcFERERaXQKI3JK76xL41BeKZFBDiaPiLe6HBERaYUURuSkDh4t4W/LUwC4+9Lu+Hips6qIiDQ+9RmROn286RCPfryNwvJKOrX3Y+KQOKtLEhGRVkphRGowDIM5n2zn9bUHABjUMYTnJw7C21ONaCIi0jQURqSGF7/Zw+trD2C3wb1junP3Jd00mJmIiDQpHWXaoM1peTz4/g9sOHC0xvQvtqbz7OJkAOaOP4/fJPZQEBERkSanlpE25rvd2dzx2gZKK1y8v+Egv7q4Kz/rH82nmw/z6ur9AEwdGc+UkfGW1ikiIm2HzTAMw+oiTqegoIDg4GDy8/MJCgqyupwW66vtGdzz1iacLjcd2vly8GhprXkSe0fwj1uG4GHXze5EROTs1Pf4rZaRNmL5zix+/eZGXG6DK/pGseDnA1m+M5uHP9pKfmkFl/SK4IbBHRjTK0JBREREmpXCSBuwKfVodRC5ekAM828agKeHnXF9o7i4RzgVbjdBGllVREQsojDSyu3JLuLWV9dTWuHioh7h/OlYEKni6+2BLxrMTERErKNLJVqx1CMl/PJfSRwtqWBAh2BevPl8vHR1jIiInGN0ZGqlDh4tYdJLa0nPL6NbRACLpg7F36GGMBEROffo6NSK5JU4+XpnFskZhfx3SzqH8krpEubPW7cn0D7AYXV5IiIidVIYaSVKnS7G/20labnHL9eNb+/HW9OHExHkY2FlIiIip6Yw0kq8mXSAtNxS2vt7c1X/aHpFBXFVv2iC/XSVjIiInNsURlqBEmclC7/ZA8CD43oycWhHiysSERGpP3VgbQXeWHuAnCInHUP9uO78DlaXIyIi0iAKIy1ccXklC7/ZC8A9l3bTpbsiItLi6DRNC5Vb7OTDjQd5Z30aucVO4tv7MWFQrNVliYiINJjCSAu0P6eYCX9fxdGSCgB8vTx4/Jq+NUZWFRERaSkURlqYsgoXM97ayNGSCrqE+XPbhZ0ZPyBG95YREZEWS2GkhXn6ix1sP1xAqL83b00fTlSwxhAREZGWTe36LciXW9N5bc0BAObfNEBBREREWgWFkRbiSFE5v/toKwB3XtyV0T0jLK5IRESkcSiMtBC//3wHR0sq6BUVyMzLelhdjoiISKNRGGkBViRn8dGmQ9hs8Mz1/fH21McmIiKth45q57j80goe/mgbANNGdmZgXIi1BYmIiDQyXU1zDssqKGPKK+s5lFdKbIgv91+u0zMiItL6KIycgypdbrYdLuCetzeSlltKWICDlyYPwd+hj0tERFofHd3OIXuzi3jog61sPpiHs9INQKf2frx+awId2/tZXJ2IiEjTUBg5h/zuo62s258LgL+3ByO6hjHvun6EBzosrkxERKTpKIycI1bvyWHt3ly8Pex8cNdIzosJwm63WV2WiIhIk1MYOQcYhsGCJbsBmDg0jn4dgi2uSEREpPno0t5zwKqUI6zbn4u3p51fX9LV6nJERESalcKIxQzD4M9LdwHwi2EdiQ72tbgiERGR5nVGYeSFF14gPj4eHx8fEhISWLdu3UnnHT16NDabrdbjqquuOuOiW5Nvd+ew4cBRHJ52fj1arSIiItL2NDiMvPvuu8ycOZO5c+eyceNGBgwYwNixY8nKyqpz/g8//JD09PTqx7Zt2/Dw8ODGG2886+JbOsMwmL/EbBW5ZXgnIoJ0F14REWl7GhxG5s+fz/Tp05k2bRp9+vRh4cKF+Pn5sWjRojrnDw0NJSoqqvqxZMkS/Pz8FEaAFcnZ/JCWh6+XB7+6WK0iIiLSNjUojDidTjZs2EBiYuLxF7DbSUxMZM2aNfV6jZdffpmf//zn+Pv7n3Se8vJyCgoKajxamxNbRSaP7KSxREREpM1qUBjJycnB5XIRGRlZY3pkZCQZGRmnXX7dunVs27aN22+//ZTzzZs3j+Dg4OpHXFxcQ8psEZbuyGLroXz8vD341UVqFRERkbarWa+mefnll+nXrx/Dhg075XyzZ88mPz+/+pGWltZMFTaft5IOADBlZDyh/t4WVyMiImKdBg16FhYWhoeHB5mZmTWmZ2ZmEhUVdcpli4uLeeedd3jiiSdO+z4OhwOHo/WetnC5Db7ffxSAq/pFW1yNiIiItRrUMuLt7c3gwYNZtmxZ9TS3282yZcsYMWLEKZd97733KC8v55e//OWZVdqK7EgvoLC8kkCHJ72jg6wuR0RExFINHg5+5syZTJkyhSFDhjBs2DAWLFhAcXEx06ZNA2Dy5MnExsYyb968Gsu9/PLLXHvttbRv375xKm/B1h+7Gd75ndrhofvPiIhIG9fgMDJx4kSys7OZM2cOGRkZDBw4kMWLF1d3ak1NTcVur9ngkpyczMqVK/nf//7XOFW3cFVhZFjnUIsrERERsZ7NMAzD6iJOp6CggODgYPLz8wkKatmnNQzDYOhTS8kpcvLenSMYGq9AIiIirVN9j9+6N00z25dTTE6RE29PO/11d14RERGFkebgdhuUOCuB46doBnYIweHpYWVZIiIi54QG9xmRhikur+SWl5PYmVHIgokDWbfPvKR3aOd2FlcmIiJyblAYaUIut8Fv3t3MxtQ8AO56cyN+XmZriPqKiIiImHSapgn9YfFOlvyYibennTG9InC5DQrLK7HbYHAntYyIiIiAwkiTMAyDv329m39+uxeA527oz0uThzB1ZDwA53dsR6CPl4UVioiInDt0mqaRVbrcPPrJNt5eZ95P54HLe3DNwFgA5o7vw9jzougSfvI7FouIiLQ1CiONqKCsgnve2sQ3u7Kx2+Cxq89j8oj46udtNhsjumoEWhERkRMpjDSSvdlF3P7a9+zNLsbHy85fJ53PZX0irS5LRETknKcw0gg2ph5l6qJ1FJRVEh3swz9vGUI/DWgmIiJSLwojjeAPX+6koKyS8zuGsPCWwUQE+lhdkoiISIuhq2nOUmZBGeuOjar611+cryAiIiLSQAojZ+nzLekYhjluSGyIr9XliIiItDgKI2fpsy2HARjfP9riSkRERFomhZGzkJZbwqbUPOw2uFJhRERE5IwojJyFz7emAzC8S3v1FRERETlDCiNn4bMfzFM0P+sfY3ElIiIiLZfCyBnak13E9sMFeNptjOsbZXU5IiIiLZbCyBn6z/fmvWcu7hFOqL+3xdWIiIi0XAojZ8BZ6eaDDQcBmDg0zuJqREREWjaFkTPw9c5McoqchAc6uKRXhNXliIiItGgKI2fg7XXmKZobB3fAy0ObUERE5GzoSNpAh/JK+XZ3NgA3DdEpGhERkbOlMNJA732fhmHAiC7tiQ/zt7ocERGRFk9hpIGqxhZRx1UREZHGoTDSAEeKytmTXQzA6J7hFlcjIiLSOiiMNMD3B44C0CMygBA/jS0iIiLSGBRGGuD7/bkADIkPtbgSERGR1kNhpAHW7zdbRobGt7O4EhERkdZDYaSeSp0uth3KB2BIJ7WMiIiINBaFkXranJZHpdsgKsiHDu18rS5HRESk1VAYqafj/UXaYbPZLK5GRESk9VAYqad1x8LIsM46RSMiItKYFEbqodLlZuOxy3rVX0RERKRxKYzUw86MQoqdLgIdnvSMCrS6HBERkVZFYaQeqvqLnN+pHR529RcRERFpTAoj9bD+gMYXERERaSoKI6dhGIZGXhUREWlCCiOncfBoKZkF5Xh52BjQIcTqckRERFodhZHTWH+sVaRvbDC+3h4WVyMiItL6KIycRtX9aIbpFI2IiEiTUBg5jfXqLyIiItKkFEZOIbfYSUpWEQCDO+lKGhERkaagMHIKG45d0tstIoBQf2+LqxEREWmdFEZOoeqSXo0vIiIi0nQURk6hur+I7kcjIiLSZBRGTsJZ6WbroXwAhqhlREREpMkojJzEnuwiKlwGQT6edAz1s7ocERGRVkth5CR2ZhQA0Cs6CJtNN8cTERFpKgojJ7EzvRCA3lGBFlciIiLSuimMnMSODDOM9IoOsrgSERGR1k1h5CR2ph87TaOWERERkSalMFKHI0XlZBWWY7NBj0iFERERkaakMFKH5GOnaDqF+uHv8LS4GhERkdbtjMLICy+8QHx8PD4+PiQkJLBu3bpTzp+Xl8eMGTOIjo7G4XDQo0cPvvjiizMquDn8WH2KRv1FREREmlqDf/a/++67zJw5k4ULF5KQkMCCBQsYO3YsycnJRERE1Jrf6XRy2WWXERERwfvvv09sbCwHDhwgJCSkMepvEjurO6/qFI2IiEhTa3AYmT9/PtOnT2fatGkALFy4kM8//5xFixbx0EMP1Zp/0aJF5Obmsnr1ary8vACIj48/u6qbWPUYI2oZERERaXINOk3jdDrZsGEDiYmJx1/AbicxMZE1a9bUucynn37KiBEjmDFjBpGRkfTt25enn34al8t10vcpLy+noKCgxqO5VLrc7MosAqC3WkZERESaXIPCSE5ODi6Xi8jIyBrTIyMjycjIqHOZvXv38v777+Nyufjiiy949NFH+dOf/sTvf//7k77PvHnzCA4Orn7ExcU1pMyzsv9IMc5KN37eHsS10zDwIiIiTa3Jr6Zxu91ERETwz3/+k8GDBzNx4kQefvhhFi5ceNJlZs+eTX5+fvUjLS2tqcustuPYyKs9owKx2zUMvIiISFNrUJ+RsLAwPDw8yMzMrDE9MzOTqKioOpeJjo7Gy8sLDw+P6mm9e/cmIyMDp9OJt7d3rWUcDgcOh6MhpTUaXUkjIiLSvBrUMuLt7c3gwYNZtmxZ9TS3282yZcsYMWJEncuMGjWKlJQU3G539bRdu3YRHR1dZxCx2tc7sgAY3KmdxZWIiIi0DQ0+TTNz5kxeeukl/v3vf7Njxw7uuusuiouLq6+umTx5MrNnz66e/6677iI3N5f77ruPXbt28fnnn/P0008zY8aMxluLRpKcUUhyZiHeHnYu6xN5+gVERETkrDX40t6JEyeSnZ3NnDlzyMjIYODAgSxevLi6U2tqaip2+/GMExcXx1dffcVvf/tb+vfvT2xsLPfddx+zZs1qvLVoJJ/9cBiAi3uGE+zrZXE1IiIibYPNMAzD6iJOp6CggODgYPLz8wkKapq+HIZhMPqPKzhwpIS/TBrE1QNimuR9RERE2or6Hr91b5pjth7K58CREny9PEjsXXskWREREWkaCiPHfLrZPEWT2CcSP2/dHE9ERKS5KIwAbrfBf7ekAzC+f7TF1YiIiLQtCiNASnYRGQVl+Hl7cHHPcKvLERERaVMURoDcYicAUcE+ODw9TjO3iIiINCaFEaCwrBKAIB9dzisiItLcFEaAgtIKAAJ91HFVRESkuSmMAIVlZhhRy4iIiEjzUxgBCqpO0/iqZURERKS5KYxwvGUkUC0jIiIizU5hBCgorerAqpYRERGR5qYwAhSWq2VERETEKgojnHBpr/qMiIiINDuFEU64tNehlhEREZHmpjDC8ZYRjTMiIiLS/BRGgIKqcUZ81TIiIiLS3BRGOD7OiFpGREREml+bDyNlFS6clW5ALSMiIiJWaPNhpKq/iM0GAd5qGREREWlubT6MVPUXCXB4YrfbLK5GRESk7WnzYaR6jBENeCYiImIJhZHq+9LoFI2IiIgV2nwYOX5fGrWMiIiIWKHNhxG1jIiIiFirzYcRDXgmIiJirTYfRjQUvIiIiLXafBipvkmewoiIiIgl2nwY0aW9IiIi1mrzYeT4fWkURkRERKygMFLdgVWnaURERKzQ5sNIoVpGRERELNXmw0hVB9YgdWAVERGxRJsPI8cHPVPLiIiIiBXadBhxuw0Ky6uuplHLiIiIiBXadBgpdlZiGObfNQKriIiINdp0GKm6rNfLw4bDs01vChEREcu06SNwVX+RIB8vbDabxdWIiIi0TW08jOi+NCIiIlZr02Gk+rJe9RcRERGxTJsOI2oZERERsV6bDiNVQ8EHOtQyIiIiYpU2HUaq79ir+9KIiIhYpk2Hkao+Ixp9VURExDptO4xUtYwojIiIiFimjYeRqpYRnaYRERGxSpsOI7qaRkRExHptPIxonBERERGrtekmgasHxNA/NpguYf5WlyIiItJmtekwMm1UZ6tLEBERafPa9GkaERERsZ7CiIiIiFhKYUREREQspTAiIiIillIYEREREUudURh54YUXiI+Px8fHh4SEBNatW3fSeV999VVsNluNh4+PzxkXLCIiIq1Lg8PIu+++y8yZM5k7dy4bN25kwIABjB07lqysrJMuExQURHp6evXjwIEDZ1W0iIiItB4NDiPz589n+vTpTJs2jT59+rBw4UL8/PxYtGjRSZex2WxERUVVPyIjI8+qaBEREWk9GhRGnE4nGzZsIDEx8fgL2O0kJiayZs2aky5XVFREp06diIuL45prrmH79u2nfJ/y8nIKCgpqPERERKR1alAYycnJweVy1WrZiIyMJCMjo85levbsyaJFi/jkk0944403cLvdjBw5koMHD570febNm0dwcHD1Iy4uriFlioiISAvS5FfTjBgxgsmTJzNw4EAuvvhiPvzwQ8LDw/nHP/5x0mVmz55Nfn5+9SMtLa2pyxQRERGLNOjeNGFhYXh4eJCZmVljemZmJlFRUfV6DS8vLwYNGkRKSspJ53E4HDgcjoaUJiIiIi1Ug1pGvL29GTx4MMuWLaue5na7WbZsGSNGjKjXa7hcLrZu3Up0dHTDKhUREZFWqcF37Z05cyZTpkxhyJAhDBs2jAULFlBcXMy0adMAmDx5MrGxscybNw+AJ554guHDh9OtWzfy8vJ47rnnOHDgALfffnvjromIiIi0SA0OIxMnTiQ7O5s5c+aQkZHBwIEDWbx4cXWn1tTUVOz24w0uR48eZfr06WRkZNCuXTsGDx7M6tWr6dOnT+OthYiIiLRYNsMwDKuLOJ2CggKCg4PJz88nKCjI6nJERESkHup7/Na9aURERMRSCiMiIiJiKYURERERsZTCiIiIiFhKYUREREQspTAiIiIillIYEREREUspjIiIiIilFEZERETEUgojIiIiYimFEREREbGUwoiIiIhYSmFERERELKUwIiIiIpZSGBERERFLKYyIiIiIpRRGRERExFIKIyIiImIphRERERGxlMKIiIiIWEphRERERCylMCIiIiKWUhgRERERSymMiIiIiKUURkRERMRSCiMiIiJiKYURERERsZTCiIiIiFhKYUREREQspTAiIiIillIYEREREUspjIiIiIilFEZERETEUgojIiIiYimFEREREbGUp9UFiFCSCz+8DXHDocNgq6tpmcqLwOUEv9DGeb2j++G7+WCzQfyFENkXcvdAxlYoywdPBziCYOAvIDCqcd5TTq28ENa8AHlp4OEF3v7Q+2qIG2Z+TtL08lLBtx04Aq2upNWxGYZhWF3E6RQUFBAcHEx+fj5BQUFWlyNnI3UtrH8Z/MOhwxDI2Q2r/wrOQrB5wJg5MOo+fbnWV1m+uf3W/B0qS6HHOBh6O3S5BOynaPgsyobDG81Q0ekC8Dj2u8Tthu9fhiVzoaL49O/fLh6mLYag6EZZHTmJfd/CJzPMg+FPRfWH4XdBvxvNkFIfrgozvHr7N26drdnW9+GD281tNmASDJ4CQbFmMKnvdm+D6nv8VhiR5uGqhG+fhW+fA8Nd+/nAaChMN/8efyEERELpUTO0dL3UfASEN/x9ncWwf5X52j7B4BsC7buZXyInBp7MH2Hln80v/Qt+Awl3Nl8gMgxYtQBWLoDul8PFsyCs28nnd7shLQm2fwRb3oWyvNrzxA2Hq/8K4T3M+Q9vNIPgoe/h4AbIP+GgFhgN502A4hxznqrnOo2CmEHmNsnZbW636P7mZ+Jyws7PIe8AhPeCqV+Af/tG3CitlLPYbNlo1wm8fE89r6sCUpbB5jdhx6fmtJCOcP5kc5/J3QvbPgRXuflcu3i46P+g/8TjB0fDMFuzKkrALwycRbDpDdjyHyjPNz/L4Diw2aGyHPzamWG218/MaZnbzM++11VmcD0T5UWQsgSydkKfayCyz/Hncnab28Tb32xx8A87s/doaoc2wCtXQmVZ3c97eIN3gLkOvX8Gw+6A4A7NW+M5SmFEGo9hwLYPYNdX5hdJ10shst+pf3mfKGMbfHafeSAE6Hs9+IbCwfVg94ARd0Ofa2Hjv+HLWce/XE9ks8MFM+GSh2u/b/ERKDwMUf2OT8v8Eb76HRxYZR44f8q3nXlw9fA2nz+4vubzPa6AC2eaX+RH9kC3MeajLm73ybeFYZgHgpP9AnWWwKf3wLb3a65r98vN+oI7gN3TrLHkCBzeDIc3QWnu8fnDe8Glj0BYT7NVY+PrZquGhwP6XH0sjB3+yRvbIKwHFGfXfC0ALz8YM9f8Qj3VZ3z0ACwad2zb94cbX4X2XWuvv8tpnooryjADZkgn88Bp9zj5NisvML/cT5wnO9k8cMUMsqblzDBg3zfmL+SgGBh0ixlqdy2G9f8yQ3afa8zHiafLnCXmvp38JaSuMbeHzQ6hXcztEBBp7o/lBeZ2KjliPgrSzRbDKkNuhcueqHmKoCQXNrxqnr4pyTGn+UfAoF+a+8/6l8z9paFCu5hhKD/N/Hf0ALjhleOfb0muGYIrSs3WmoPrIf0H8zML624Gn9y9kL3TDLhV/6c9vOHSR6HLaFj6GOxZVvN9QzqaQdrb3/wBUVkOI+85+f+9+sg/aH5mlWXm/uTlZ35+QbEQ0QccAadevuAw/PMSc//tPtZshVr3Euz52myNrIvNAwb8HK6aD14+Z177mXK7IetHc3/zDze3n0WnlhRGpHFk/ghf/B8cWFlzengvmPjmqX/BO4th+dOw9kUwXOAIhp/Nh343nPr9dn4O3n7gEwI5u8wvrIyt5vPnXQfXvggYkL7F/CLe9oH5ZXfZkzDqXvOL8h8XHf8iDelo1lteaH7JH9lj1lODzTxwR/WDb56tO8B0HQOXPwmR55n/Liswt03yFzD2aTj/lprz7/vWDGG5+yBmoLm8tx8UZUFRpvln7l7zS9fuCRc/ZLZgJH9x8u1TxREMva40Q1z3y2oetPPS4L+/gZSlx6d5B0Lni8w+ObFDzHp8gqHSaR5Md//P/HLumAAdhtb/iyt7F7wyztyuHg6zVcm3nfkZHtpoBjHq+Irx8jPf55KHzfcsyYUV8+DHT8zXcleCX3vz1EPHEbDxteMHrtjBZgtA9EDztYsyzcCVusacduH9pw5RBelmnxjfEDMUB0TUDDdb3zfrHjDJbGEwDNj6Hnz3J/PgWsVmN1uVCg7VfH27J/S80gwPzmJYPLtmS5SX37HtUg/+4eY2GDDJbJU6GWexefpz9V+hOKvmc54+Zp0lR8yDe88rzFMM0QPNIJF/0FwXT29ITYJ1/zze2ubpawaI8nxzH+oxFg6uq/t00am062zWkLq65nS7pxmeKkrMU4517Ss2OyQ+BiPvrX8IrSiFrB3w/SL44R1wV9Q9n4c3dBpphqPAaPM7BwNK88zwsX8VHFhthvvw3nDb/8DnhGOQq8L8XnEWmS1AR1LMALjvW/P5fjfCdS81X3h2lpgt0JveMH9o/HQ9AyLN/9uRfc19qhmCksKINEx5oXnQDOtxfAfd9RW8c7P5H9nTFwZPNb/E939n/ufzCYGbXjMPats/NP8zXva4ubO73fDmDccPIH2ugXHPmL9IzsSmN+Gze82DlE+wGQTq+uK6YRFsfss8EId2gUnvmOt04pdBRZl5UMlLNUOJ4Ta/mKt+9aVvMVsrju6DmPPNDppb3z/+hRZ/obk+a14w56ky7hnzV9ORPbDqefPXcH34hprbsfOFx9//wCrzIJF/0FzPqmbgqL4QPcgMTZ7eJ39NwzA/k4MbzNftcknTffHk7oXP7zd/KZ6MzW4edHyCzVM7JzZ3dz92gCs9eur3sdnN7XCypvIqPa+C6/55/BevYZghb9uH5mmP7B015+96qRmsvf3M0xcfTjenR/SBix6A718x93kAL3/of6O5zlUHHEcwDL3V/P+w7QPI2FK7puA4GP7rYy1eXc0gmvWj+fkWZ5nr7gg2W1T82h9/hHVvWH+ESifs+tIM6fmHzIPhkGnHT38YxukPjOWFZph0BJkH6dKj8MFtZtg7kXeAearJL8wMiLGDzBCQs9sMPqGdzf97sYPNbQlmqFw82zy497nW7CNW9f+uvNBsYUlbb/6/DIw2/735TfP5yL7mZ1+cbX4OAeHm/x1PhxlqKsvNQFOcbe5jJ54O7jTK/EHirjTfp+CwOU/VqeHTadcZbvnIXKf62L0U3p5ovt/o2TD6oeP1+Yef+jMwDCjMgKztkLnd3P4xg6DDMLPulCVmK5RfqPkDoqqVp6IU/veIuV5ght64BPPfuXtrv09gDIyYYW7rqhbX25ac2enwU1AYkdPL2Gr+atj7jbnjG27zAD7hn+aXxZs3mS0O3RLhZ382WxjA/CJ95xe1T22A+WX787dh7d9hyaNmiLnp3+YvqrO19xt49xbzVxqYX/7dL4eEX5kHkXX/OD6vpy/cvtQ8eDeG3L2w9HHzl/uJISg4zgwnP7xl/rt9dziy+/jzQ24z/8OnJZkHL5vd/CUeEHn8z6h+5kG6JTMMsw/LqgXmL+heV5otQX6hx4NUdSdZl3nAWvM38xdc1faM6AOJj5stTz7B5sFv81vm6b1uieYvY29/c7kNr5rh12YzXzsuwewfk/RPc5+N6AMdh5u/XFPX1vxMsJn7cnnhsQBkQLfL4JLZ8MpVZtO7h6Pm6UJPX7jofvPUVdVndWSP+eu780U1fy1nbjcDzA/vmAfPUfearTUtubOoq9IM14UZ5naNG3bmzf6FmWbLS3jP089rGOYpsMUPmQf2hvBtBx1Hmh3iOybU/dpH9pitglVhuDTP3Kd8Qsx9N+Z86HIxRJxX/9PSVTb82/wBBeb3Qu7eYy3EQWYwsnuarWoluWZw9mtv7q95qSc//VMfQbEwbp55qtnT21zP7GRIW2v+iCs9avY1+2mLHsDNH0D3xDN/7zoojEjdygrML8kNr5oB5ERVX8An/gLteZUZJn7666yizOzdv+1984u62xjzV2dlqdlEvft/5pfH+OfNFpXGUnrUPJCFdjH/81b9wnC7zKCS/Ln572sXwsBJjfe+VfLSzAPo1vcg9ny48jnzi+ubP5inGcA8X9z5IvNXdfwFjV9Da5K+xQyusYNh8LTjgeVMpa0zg/KJTdRg7qO9rjQ7ZnYZfbxPR+paeH2CeZrA7mnus13HmC0rXz9p/pLvdhlc+azZv6MhKo614FjRZ6C1yU42fzxVhXhnkdnhuvTosSuDys3PuLqTevfap9+ssGSO2UraUDY7hHY1f0w5gswOtJnbzQDY5WKzpae8yAwUBYfNR2muean3pQ+fPihWlsOm12HLe+Z2ihlknrqNHVIzWDcChRGpKTvZ7HT1w9vmf2QwA0ePcXDeteZ5eS8/+PJBMzWD2Xw96Z2T96Kv6qkf2sVM9js+MwNB1S/dPtfAjf9u3vOlS441+w6/q3ne80Q/fmo2w/a8UleWWCn/EGx5xzxI2T0guKPZT+JkX7Ipy+CtieZpuHbxMH358bBSWX7mV5GIuN1mHzBPH4jobZ4uO5JyvO9RUOyxq5wKzRYSm9280iqoQ+3TsM4S8zv7bAN7M1MYaYtclWafjuJs81GSY/562L/SvAqgSvvuMGw69L/JbMr8qZ1fmJf0jbjbPI/eEGteMK9iCY6DO7+r+/VFzjW7l5i/FEf/DiJ6WV2NSKuhMNLW7F1hdro8WS93m938xT5sOnS+uOlaK6o6C7br3HijgYqISItU3+N3y2rvkdqcJfC/h81L2MA8bxoYZfbY9g83mwVD4syBkKo6oDYlm808/y8iIlJPCiNnyjDMZt3w3hA31Lo6vnzQrAPMkRMTHz/9ID4iIiLnEN2190zt+so8LfL6tWY/jcaQtQPemwab3zavDjmdgxuOB5FJ78JVf1IQERGRFkdh5ExtfM3801kEH88we02fjcJMeOMGc6Cqj++EhRfWHkTqwBr4/AHz0la3G76435w+4BfQc9zZvb+IiIhFFEbORGGmOYQ2mJdsHVgJSQvP/PUqyuDdm6HgoHkVik+wOQbI69eZHVPBvOzr3ZvNoYZfHAXv/tIcMc8RZA6VLCIi0kIpjNTXiS0fW94xR9LrMNQc6Q5g2ePmfToaoigbdvwX/jPZHM3UJxhu+Rju3WwOlYwBn9xjjhS57HFziGVPH3OAn6rBvUbPhsDIs18/ERERiyiM1Mf+VfBcF/N0TGW5eVdUMO/aOXiaOWJjZRl88YDZsfV0KsvN/iZ/7Ga2duz+yhy188Z/mzee8wuFa/5mDtaUn2q2gmx41Vz2lo/M4dr9I8yhjodNb7LVFhERaQ5nFEZeeOEF4uPj8fHxISEhgXXr1tVruXfeeQebzca11157Jm9rDcMw74tQehQ2v2HeDfbIbnO00vMmmJeyXvUncyj1fd+Yo5CeSlEW/Hv88T4n4b3N4dKnfAZdLzk+nyMQrvmr+feqUzUDbzbvvDhgIjywC6Z+3rCbaImIiJyDGhxG3n33XWbOnMncuXPZuHEjAwYMYOzYsWRlZZ1yuf379/PAAw9w4YUXnnGxltjxmXkXTi9/s39G1TC+5004Prx0aGfzZlgAXz1s3j3xp/JS4dvnzDCTlmTeofOXH8KMteb9W+JH1V6my2jzNuRg3v/ksieOP2ezNfzGTSIiIuegBh/N5s+fz/Tp05k2bRp9+vRh4cKF+Pn5sWjRopMu43K5uPnmm3n88cfp0qXLWRXcrNwuWP60+fcRM+DWxeY9A7CZd2M90QW/NZ/LT4WVC45PL82D92+FBf3g69+bt6wO7QrTl5k3lzudy39vvvbE14/fBlxERKQVadCgZ06nkw0bNjB79uzqaXa7ncTERNasWXPS5Z544gkiIiK47bbb+O677077PuXl5ZSXH799d0FBQUPKbDzbPoTsHWbH0hEzzLtB/nqNeYfEn96/wtsfLn8S3p8G3zxj3kCu/42wZC7kHQBs0PlCGDDJ7Jxa33u+ePvrahkREWnVGhRGcnJycLlcREbWvHojMjKSnTt31rnMypUrefnll9m8eXO932fevHk8/vjjDSmt8bldZqgAGHmvGUTAPDVzsrt/njfBPAWz7p/m1S5VV7yEdIIbX9Ew6SIiInVo0k4HhYWF3HLLLbz00kuEhdX/FMPs2bPJz8+vfqSlpTVhlSex83PzVs++7SDhV/VbxmaDK/4Av04ygwk2sxXkV98qiIiIiJxEg1pGwsLC8PDwIDMzs8b0zMxMoqKias2/Z88e9u/fz/jx46unuY+N1+Hp6UlycjJdu3attZzD4cDhcDSktMa3+tiVLENvN69saYjwHnDjq3BtGXj5NHppIiIirUmDWka8vb0ZPHgwy5Ytq57mdrtZtmwZI0aMqDV/r1692Lp1K5s3b65+XH311VxyySVs3ryZuLi4s1+DppCaBAfXgYc3DD2LcTwURERERE6rwXftnTlzJlOmTGHIkCEMGzaMBQsWUFxczLRp0wCYPHkysbGxzJs3Dx8fH/r27Vtj+ZCQEIBa088pa461ivSfqNFNRUREmliDw8jEiRPJzs5mzpw5ZGRkMHDgQBYvXlzdqTU1NRV7Sx7/4sgec4h2gBF3W1uLiIhIG2AzjPqMX26tgoICgoODyc/PJyjoJFeyNJbFs2Ht36H7WLj5P037XiIiIq1YfY/fLbgJowm4XbD1ffPvQ2879bwiIiLSKBRGTrTvWyjOAt9Q6Hqp1dWIiIi0CQojJ9p2rFWkzzW6AZ2IiEgzURipUlkOPx67426/G6ytRUREpA1RGKmyewmU50NgDHQcaXU1IiIibYbCSJWqUzR9r4OWfGmyiIhIC6OjLkB5ESQvNv/e93praxEREWljFEYAUtdAZSmEdISYQVZXIyIi0qYojACkrjX/7DTKvPOuiIiINBuFEYC0JPPPuARr6xAREWmDFEZcFXBog/n3jsOtrUVERKQNUhjJ2AoVJeATDGE9ra5GRESkzVEYOfEUjS7pFRERaXY6+lZ1Xo0bZm0dIiIibVTbDiOGcULLiPqLiIiIWKFth5H8NChMB7snxA62uhoREZE2qW2HkdRjrSJR/cHbz9paRERE2qi2HUY0voiIiIjl2ngYOdZ5taPCiIiIiFU8rS7AUiPugQOroOMIqysRERFps9p2GBkw0XyIiIiIZdr2aRoRERGxnMKIiIiIWEphRERERCylMCIiIiKWUhgRERERSymMiIiIiKUURkRERMRSCiMiIiJiKYURERERsZTCiIiIiFhKYUREREQspTAiIiIillIYEREREUu1iLv2GoYBQEFBgcWViIiISH1VHberjuMn0yLCSGFhIQBxcXEWVyIiIiINVVhYSHBw8EmftxmniyvnALfbzeHDhwkMDMRmszXa6xYUFBAXF0daWhpBQUGN9rotibaBtgFoG7T19QdtA9A2gMbfBoZhUFhYSExMDHb7yXuGtIiWEbvdTocOHZrs9YOCgtrsjldF20DbALQN2vr6g7YBaBtA426DU7WIVFEHVhEREbGUwoiIiIhYqk2HEYfDwdy5c3E4HFaXYhltA20D0DZo6+sP2gagbQDWbYMW0YFVREREWq823TIiIiIi1lMYEREREUspjIiIiIilFEZERETEUgojIiIiYqk2HUZeeOEF4uPj8fHxISEhgXXr1lldUpOYN28eQ4cOJTAwkIiICK699lqSk5NrzDN69GhsNluNx5133mlRxY3vscceq7V+vXr1qn6+rKyMGTNm0L59ewICArj++uvJzMy0sOLGFx8fX2sb2Gw2ZsyYAbTOfeDbb79l/PjxxMTEYLPZ+Pjjj2s8bxgGc+bMITo6Gl9fXxITE9m9e3eNeXJzc7n55psJCgoiJCSE2267jaKiomZci7Nzqm1QUVHBrFmz6NevH/7+/sTExDB58mQOHz5c4zXq2neeeeaZZl6TM3O6fWDq1Km11m3cuHE15mnN+wBQ5/eCzWbjueeeq56nqfeBNhtG3n33XWbOnMncuXPZuHEjAwYMYOzYsWRlZVldWqP75ptvmDFjBmvXrmXJkiVUVFRw+eWXU1xcXGO+6dOnk56eXv149tlnLaq4aZx33nk11m/lypXVz/32t7/ls88+47333uObb77h8OHDXHfddRZW2/jWr19fY/2XLFkCwI033lg9T2vbB4qLixkwYAAvvPBCnc8/++yz/OUvf2HhwoUkJSXh7+/P2LFjKSsrq57n5ptvZvv27SxZsoT//ve/fPvtt9xxxx3NtQpn7VTboKSkhI0bN/Loo4+yceNGPvzwQ5KTk7n66qtrzfvEE0/U2Dfuueee5ij/rJ1uHwAYN25cjXV7++23azzfmvcBoMa6p6ens2jRImw2G9dff32N+Zp0HzDaqGHDhhkzZsyo/rfL5TJiYmKMefPmWVhV88jKyjIA45tvvqmedvHFFxv33XefdUU1sblz5xoDBgyo87m8vDzDy8vLeO+996qn7dixwwCMNWvWNFOFze++++4zunbtarjdbsMwWv8+ABgfffRR9b/dbrcRFRVlPPfcc9XT8vLyDIfDYbz99tuGYRjGjz/+aADG+vXrq+f58ssvDZvNZhw6dKjZam8sP90GdVm3bp0BGAcOHKie1qlTJ+PPf/5z0xbXDOpa/ylTphjXXHPNSZdpi/vANddcY1x66aU1pjX1PtAmW0acTicbNmwgMTGxeprdbicxMZE1a9ZYWFnzyM/PByA0NLTG9DfffJOwsDD69u3L7NmzKSkpsaK8JrN7925iYmLo0qULN998M6mpqQBs2LCBioqKGvtDr1696NixY6vdH5xOJ2+88Qa33nprjTtht/Z94ET79u0jIyOjxuceHBxMQkJC9ee+Zs0aQkJCGDJkSPU8iYmJ2O12kpKSmr3m5pCfn4/NZiMkJKTG9GeeeYb27dszaNAgnnvuOSorK60psAmsWLGCiIgIevbsyV133cWRI0eqn2tr+0BmZiaff/45t912W63nmnIfaBF37W1sOTk5uFwuIiMja0yPjIxk586dFlXVPNxuN7/5zW8YNWoUffv2rZ7+i1/8gk6dOhETE8OWLVuYNWsWycnJfPjhhxZW23gSEhJ49dVX6dmzJ+np6Tz++ONceOGFbNu2jYyMDLy9vWt9+UZGRpKRkWFNwU3s448/Ji8vj6lTp1ZPa+37wE9VfbZ1fQ9UPZeRkUFERESN5z09PQkNDW2V+0ZZWRmzZs1i0qRJNe7Yeu+993L++ecTGhrK6tWrmT17Nunp6cyfP9/CahvHuHHjuO666+jcuTN79uzhd7/7HVdccQVr1qzBw8Ojze0D//73vwkMDKx1mrqp94E2GUbashkzZrBt27Ya/SWAGuc/+/XrR3R0NGPGjGHPnj107dq1uctsdFdccUX13/v3709CQgKdOnXiP//5D76+vhZWZo2XX36ZK664gpiYmOpprX0fkFOrqKjgpptuwjAMXnzxxRrPzZw5s/rv/fv3x9vbm1/96lfMmzevxd/H5ec//3n13/v160f//v3p2rUrK1asYMyYMRZWZo1FixZx88034+PjU2N6U+8DbfI0TVhYGB4eHrWulsjMzCQqKsqiqpre3XffzX//+1+WL19Ohw4dTjlvQkICACkpKc1RWrMLCQmhR48epKSkEBUVhdPpJC8vr8Y8rXV/OHDgAEuXLuX2228/5XytfR+o+mxP9T0QFRVVq1N7ZWUlubm5rWrfqAoiBw4cYMmSJTVaReqSkJBAZWUl+/fvb54Cm1GXLl0ICwur3u/byj4A8N1335GcnHza7wZo/H2gTYYRb29vBg8ezLJly6qnud1uli1bxogRIyysrGkYhsHdd9/NRx99xNdff03nzp1Pu8zmzZsBiI6ObuLqrFFUVMSePXuIjo5m8ODBeHl51dgfkpOTSU1NbZX7wyuvvEJERARXXXXVKedr7ftA586diYqKqvG5FxQUkJSUVP25jxgxgry8PDZs2FA9z9dff43b7a4Oay1dVRDZvXs3S5cupX379qddZvPmzdjt9lqnL1qDgwcPcuTIker9vi3sA1VefvllBg8ezIABA047b6PvA03WNfYc98477xgOh8N49dVXjR9//NG44447jJCQECMjI8Pq0hrdXXfdZQQHBxsrVqww0tPTqx8lJSWGYRhGSkqK8cQTTxjff/+9sW/fPuOTTz4xunTpYlx00UUWV9547r//fmPFihXGvn37jFWrVhmJiYlGWFiYkZWVZRiGYdx5551Gx44dja+//tr4/vvvjREjRhgjRoywuOrG53K5jI4dOxqzZs2qMb217gOFhYXGpk2bjE2bNhmAMX/+fGPTpk3VV4o888wzRkhIiPHJJ58YW7ZsMa655hqjc+fORmlpafVrjBs3zhg0aJCRlJRkrFy50ujevbsxadIkq1apwU61DZxOp3H11VcbHTp0MDZv3lzj+6G8vNwwDMNYvXq18ec//9nYvHmzsWfPHuONN94wwsPDjcmTJ1u8ZvVzqvUvLCw0HnjgAWPNmjXGvn37jKVLlxrnn3++0b17d6OsrKz6NVrzPlAlPz/f8PPzM1588cVayzfHPtBmw4hhGMZf//pXo2PHjoa3t7cxbNgwY+3atVaX1CSAOh+vvPKKYRiGkZqaalx00UVGaGio4XA4jG7duhn/93//Z+Tn51tbeCOaOHGiER0dbXh7exuxsbHGxIkTjZSUlOrnS0tLjV//+tdGu3btDD8/P2PChAlGenq6hRU3ja+++soAjOTk5BrTW+s+sHz58jr3/SlTphiGYV7e++ijjxqRkZGGw+EwxowZU2vbHDlyxJg0aZIREBBgBAUFGdOmTTMKCwstWJszc6ptsG/fvpN+PyxfvtwwDMPYsGGDkZCQYAQHBxs+Pj5G7969jaeffrrGwfpcdqr1LykpMS6//HIjPDzc8PLyMjp16mRMnz691o/S1rwPVPnHP/5h+Pr6Gnl5ebWWb459wGYYhtE4bSwiIiIiDdcm+4yIiIjIuUNhRERERCylMCIiIiKWUhgRERERSymMiIiIiKUURkRERMRSCiMiIiJiKYURERERsZTCiIiIiFhKYUREREQspTAiIiIilvp/L+yvnuG8q/4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "LamdaMART.fit(print_training='print')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}